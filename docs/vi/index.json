[
{
	"uri": "http://localhost:1313/fcj-workshop/vi/",
	"title": "Báo cáo thực tập",
	"tags": [],
	"description": "",
	"content": "Báo cáo thực tập Thông tin sinh viên: Họ và tên: Lý Hoàng Sơn\nSố điện thoại: 0853596459\nEmail: lyhoangson21102005@gmail.com\nTrường: Đại học FPT Hồ Chí Minh\nNgành: Kỹ thuật phần mềm\nLớp: AWS082025\nCông ty thực tập: Công ty TNHH Amazon Web Services Vietnam\nVị trí thực tập: FCJ Cloud Intern\nThời gian thực tập: Từ ngày 06/09/2025 đến ngày 12/24/2025\nNội dung báo cáo Worklog Proposal Các bài blogs đã dịch Các events đã tham gia Workshop Tự đánh giá Chia sẻ, đóng góp ý kiến "
},
{
	"uri": "http://localhost:1313/fcj-workshop/vi/3-blogstranslated/3.1-blog1/",
	"title": "Blog 1",
	"tags": [],
	"description": "",
	"content": "Rox tăng tốc năng suất bán hàng với AI agents được hỗ trợ bởi Amazon Bedrock viết bởi Santhan Pamulapati, Andrew Brown, Santhosh Kumar Manavasi Lakshminarayana, Shriram Sridharan, và Taeuk Kang | vào ngày 1 tháng 10 năm 2025 | trong mục Amazon Bedrock, Amazon Machine Learning, Customer Solutions\nBài viết này được đồng tác giả bởi Shriram Sridharan, Taeuk Kang, và Santhosh Kumar Manavasi Lakshminarayanan từ Rox.\nRox đang xây dựng một hệ thống điều hành doanh thu cho kỷ nguyên ứng dụng AI.\nCác đội ngũ kinh doanh hiện đại phụ thuộc vào nhiều dữ liệu hơn bao giờ hết, chẳng hạn như hệ thống quản lý quan hệ khách hàng (CRM), tự động hóa marketing, hệ thống tài chính, phiếu hỗ trợ, và dữ liệu sử dụng sản phẩm trực tiếp. Mặc dù mỗi hệ thống đều có vai trò riêng, nhưng khi kết hợp lại, chúng tạo silos làm chậm người bán và bỏ lỡ những điều sâu sắc chưa được khai thác.\nRox giải quyết vấn đề này bằng cách cung cấp một hệ thống điều hành doanh thu: một lớp thống nhất giúp kết nối các tín hiệu này lại với nhau và trang bị AI agents để thực thi các luồng công việc go-to-market (GTM). Thay vì đối chiếu báo cáo hoặc cập nhật các trường dữ liệu, nhân viên bán hàng nhận thông tin theo thời gian thực và tự động hóa trong luồng công việc hằng ngày của họ.\nHôm nay, chúng tôi vui mừng thông báo rằng Rox đã phát hành rộng rãi, với cơ sở hạ tầng Rox được xây dựng trên AWS và được cung cấp trên web, Slack, macOS, và iOS. Trong bài viết này, chúng tôi chia sẻ cách Rox tăng tốc năng suất bán hàng với AI agents được hỗ trợ bởi Amazon Bedrock.\nTổng quan giải pháp Như đã ghi trong Rox is transforming revenue teams with AI-driven integration powered by AWS, các đội ngũ GTM hiện đại cần nhiều hơn một cơ sở dữ liệu tĩnh. Dữ liệu doanh thu trải dài trên nhiều hệ thống, như là dữ liệu sử dụng sản phẩm, tài chính và hỗ trợ, và các đội ngũ cần một hệ thống có thể thống nhất bối cảnh và hành động dựa trên nó theo thời gian thực.\nRox mang lại điều này thông qua một kiến trúc phân lớp trên AWS:\nSystem of record - Một đồ thị tri thức thống nhất, có quản trị sẽ kết hợp từ CRM, tài chính, hỗ trợ, đo lường sản phẩm từ xa, và dữ liệu web. Agent swarms - Các agents thông minh, nhận biết bối cảnh khách hàng, có khả năng suy luận trên đồ thị và điều phối các luồng công việc đa bước như nghiên cứu, tiếp cận, quản lý cơ hội, và tạo đề xuất. Interfaces across surfaces - Người bán hàng tương tác trong luồng công việc này ở nơi họ làm việc, như là web application, Slack, iOS, và macOS Điều này chuyển đổi CRM từ một hệ thống ghi nhận thụ động thành một hệ thống hành động chủ động, để các đội ngũ có thể hành động dựa trên dữ liệu của họ ngay lập tức và một cách thông minh.\nSơ đồ dưới đây minh họa kiến trúc giải pháp.\nLợi ích và đặc điểm của ROX Hiện đã phát hành rộng rãi, Rox mở rộng từ việc intelligence đến thực thi toàn diện với Command, một conversational interface mới có thể điều phối các luồng công việc multi-agent. Command kết hợp với nhiều agents đặc biệt chạy song song.\nMột yêu cầu (ví dụ, “chuẩn bị cho tôi về gia hạn ACME và soạn thảo follow-ups”) được mở rộng thành một kế hoạch:\nNghiên cứu tín hiệu sử dụng và hỗ trợ Xác định các stakeholders còn thiếu Soạn thảo nội dung tiếp cận Cập nhật cơ hội Tập hợp thành một bản đề xuất Một bước được hoàn thành thông qua tool calls trong hệ thống của bạn và phải tuân theo các phê duyệt từ guardrail. Comprehensive safety architecture của chúng tôi sử dụng một hệ thống guardrail đa lớp tinh vi làm tuyến phòng thủ đầu tiên chống lại yêu cầu không phù hợp, có hại hoặc độc hại. Các yêu cầu đầu vào trải qua quá trình phân tích nghiêm ngặt thông qua cơ chế lọc tiên tiến của chúng tôi trước khi đến inference layer. Giai đoạn tiền xử lý đánh giá nhiều khía cạnh về an toàn và sự thích hợp, như là legal compliance assessment và business relevance evaluation, để chắc chắn chỉ những yêu cầu hợp pháp, an toàn, và phù hợp bối cảnh mới được tiến hành đến model execution.\nCommand phân rã yêu cầu, định tuyến các bước đến đúng các agents, sắp xếp external tool invocations (CRM, calendar, enrichment, email), tổng hợp kết quả vào hệ thống bối cảnh, và trả về luồng mạch lạc sẵn sàng để sử dụng trên web, Slack, iOS, hoặc macOS. Mỗi đề nghị đều có thể giải thích (sources và traces), có thể đảo ngược (audit logs), và nhận biết chính sách (role-based access control, rate limits, required approvals).\nAmazon Bedrock cung cấp sức mạnh cho Rox như thế nào Command đòi hỏi một mô hình có khả năng suy luận qua nhiều bước, điều phối các công cụ, và thích ứng linh hoạt.\nĐể đáp ứng các yêu cầu, Rox chọn Anthropic’s Claude Sonnet 4 trên Amazon Bedrock. Anthropic’s Claude Sonnet 4 đã liên tục chứng tỏ hiệu suất vượt trội về tool-calling và suy luận, cho phép các agent của Rox sắp xếp các luồng công việc như nghiên cứu tài khoản, làm giàu dữ liệu, tiếp cận, quản lý cơ hội, và tạo đề xuất một cách đáng tin cậy.\nAmazon Bedrock cung cấp nền tảng để triển khai Rox ở quy mô doanh nghiệp, mang lại bảo mật, linh hoạt để tích hợp với các models mới nhất, và khả năng mở rộng để xử lý hàng ngàn agents đồng thời một cách đáng tin cậy.\nCác tính năng bổ sung Ngoài Command, Rox bao gồm những tính năng sau:\nTính năng Mô tả Research Cung cấp nghiên cứu sâu về tài khoản và thị trường, dựa trên unified context (kế thừa từ private beta) Meet Cho phép ghi âm, chuyển mã, tóm tắt và biến các cuộc họp thành hành động (kế thừa từ private beta) Outreach Cung cấp tương tác với khách hàng tiềm năng được cá nhân hóa, đặt trong bối cảnh từ unified data (mới) Revenue Giúp bạn theo dõi, cập nhật, và thúc đẩy pipelines trong luồng công việc (mới) Auto-fill proposals Giúp bạn tập hợp các đề xuất được tùy chỉnh trong vài giây từ account context (mới) Rox apps Cung cấp modular extensions để giúp bổ sung các luồng công việc được xây dựng có mục đích (dashboards, trackers) trực tiếp vào hệ thống (mới) iOS app Cung cấp thông báo và chuẩn bị cuộc họp khi đang di chuyển (mới) Mac app Mang lại khả năng chuyển mã các cuộc gọi và thêm chúng vào hệ thống bối cảnh (mới) Regional expansion Hiện đã có mặt tại AWS Middle East (Bahrain) AWS Region, phù hợp với nhu cầu về data residency và sovereignty (mới) Tác động ban đầu đến khách hàng Trong giai đoạn beta, các doanh nghiệp đã thấy được lợi ích ngay lập tức:\nNăng suất của nhân viên đại diện cao hơn 50% Tốc độ bán hàng nhanh hơn 20% Doanh thu mỗi nhân viên đại diện tăng gấp hai lần Ví dụ, các khách hàng thực tế của Rox đã có thể tập trung sắc bén hơn vào các cơ hội có giá trị cao, thúc đẩy mức tăng 40 - 50% trong giá bán trung bình. Các khách hàng khác đã giảm 90% thời gian chuẩn bị của nhân viên và chốt giao dịch nhanh hơn, cộng thêm 15% giao dịch trị giá sáu con số được khám phá thông qua những hiểu biết của Rox. Rox cũng rút ngắn ramp time cho nhân viên mới, với khách hàng báo cáo ramp time nhanh hơn 50% khi sử dụng Rox.\nThử Rox ngay hôm nay Tầm nhìn của chúng tôi là các đội ngũ kinh doanh sẽ vận hành với một agent swarm luôn hoạt động, liên tục nghiên cứu tài khoản, tương tác với stakeholders, và thúc đẩy pipeline tiến lên.\nRox hiện đã phát hành rộng rãi. Hãy bắt đầu tại rox.com hoặc truy cập AWS Marketplace. Cùng với AWS, chúng tôi sẽ tiếp tục xây dựng hệ thống điều hành dựa trên AI cho các đội ngũ kinh doanh hiện đại.\nVề các tác giả Shriram Sridharan là Co-Founder/Engineering Head của Rox, một công ty AI được Sequoia hậu thuẫn. Trước Rox, Shriram đã lãnh đạo data infrastructure team tại Confluent, chịu trách nhiệm làm cho Kafka nhanh hơn và rẻ hơn trên các đám mây. Trước đó, anh là một trong những kỹ sư đời đầu tại Amazon Aurora (pre-launch) tái định hình cơ sở dữ liệu cho đám mây. Aurora là Dịch vụ AWS phát triển nhanh nhất và đã nhận được giải thưởng hệ thống SIGMOD năm 2019.\nTaeuk Kang là Founding Engineer tại Rox, làm việc trong lĩnh vực nghiên cứu và kỹ thuật AI. Anh học Khoa học Máy tính tại Stanford. Trước Rox, anh đã xây dựng các large language model agents và retrieval-augmented generation systems tại X (trước đây là Twitter) và thiết kế distributed LLM infrastructure cung cấp năng lượng cho các tính năng cốt lõi của sản phẩm và Trust \u0026amp; Safety, cải thiện sức khỏe tổng thể của nền tảng. Trước đó tại Stripe, anh đã phát triển các streaming and batch data processing pipelines hiệu suất cao tích hợp Apache Flink, Spark, Kafka, và AWS SQS.\nSanthosh Kumar Manavasi Lakshminarayanan lãnh đạo Platform tại Rox. Trước Rox, anh là Director of Engineering tại StreamSets, được IBM mua lại, lãnh đạo StreamSets Cloud Platform giúp các doanh nghiệp lớn vận hành data pipeline của họ ở quy mô lớn trên các nhà cung cấp đám mây hiện đại. Trước StreamSets, anh là senior engineer tại Platform Metadata team tại Informatica.\nAndrew Brown là Account Executive cho AI Startups tại Amazon Web Services (AWS) ở San Francisco, CA. Với nền tảng vững chắc về cloud computing và tập trung vào việc hỗ trợ các startup, Andrew chuyên giúp các công ty mở rộng quy mô hoạt động của họ bằng cách sử dụng các công nghệ của AWS.\nSanthan Pamulapati là Sr. Solutions Architect cho GenAI startups tại AWS, với chuyên môn sâu về thiết kế và xây dựng các giải pháp có khả năng mở rộng nhằm thúc đẩy tăng trưởng của khách hàng. Anh có nền tảng vững chắc trong việc xây dựng các hệ thống HPC tận dụng các dịch vụ của AWS và đã làm việc với các khách hàng chiến lược để giải quyết các thách thức kinh doanh.\n"
},
{
	"uri": "http://localhost:1313/fcj-workshop/vi/3-blogstranslated/3.2-blog2/",
	"title": "Blog 2",
	"tags": [],
	"description": "",
	"content": "Cách Laravel Nightwatch xử lý hàng tỷ sự kiện observability theo thời gian thực với Amazon MSK và ClickHouse Cloud bởi Masudur Rahaman Sayem, James Carpenter, Jess Archer, và Johnny Mirza | vào ngày 01 THÁNG 10 NĂM 2025 | trong mục Amazon Managed Streaming for Apache Kafka (Amazon MSK), Analytics, Expert (400), Technical How-to\nLaravel, một trong những web framework phổ biến nhất thế giới, đã ra mắt nền tảng observability của riêng mình, Laravel Nightwatch, để cung cấp cho các nhà phát triển những hiểu biết sâu sắc theo thời gian thực về hiệu suất ứng dụng. Được xây dựng hoàn toàn trên các dịch vụ được quản lý của AWS và ClickHouse Cloud, dịch vụ này đã xử lý hơn một tỷ events mỗi ngày trong khi vẫn duy trì độ trễ truy vấn dưới một giây, mang lại cho các nhà phát triển khả năng hiển thị tức thì về tình trạng ứng dụng của họ.\nBằng cách kết hợp Amazon Managed Streaming for Apache Kafka (Amazon MSK) với ClickHouse Cloud và AWS Lambda, Laravel Nightwatch cung cấp high-volume, low-latency monitoring ở quy mô lớn, trong khi đó vẫn duy trì sự đơn giản và trải nghiệm của nhà phát triển mà Laravel vốn nổi tiếng.\nThách thức: Cung cấp real-time monitoring cho một cộng đồng nhà phát triển toàn cầu Framework Laravel cung cấp năng lượng cho hàng triệu ứng dụng trên toàn thế giới, phục vụ hàng tỷ yêu cầu mỗi tháng. Mỗi yêu cầu có thể tạo ra hàng trăm observability events, chẳng hạn như database queries, queued jobs, cache lookups, emails, notifications, và exceptions. Đối với việc ra mắt của Nightwatch, Laravel đã dự đoán sự chấp nhận ngay lập tức từ cộng đồng toàn cầu của mình, với hàng chục nghìn ứng dụng gửi events liên tục từ ngày đầu tiên.\nLaravel Nightwatch cần một kiến trúc có thể:\nTiếp nhận hàng triệu JSON events mỗi giây từ các ứng dụng của khách hàng một cách đáng tin cậy. Cung cấp các truy vấn phân tích dưới một giây cho các real-time dashboards. Mở rộng theo chiều ngang để xử lý các đột biến lưu lượng không thể đoán trước. Cung cấp tất cả những điều này một cách hiệu quả về chi phí và ít phải bảo trì. Thách thức là xử lý dữ liệu ở quy mô toàn cầu và cung cấp những hiểu biết sâu sắc về tình trạng ứng dụng mà không ảnh hưởng đến trải nghiệm thiết lập đơn giản cho các nhà phát triển.\nGiải pháp: Một decoupled streaming và analytics pipeline Laravel Nightwatch đã triển khai một kiến trúc dual-database, streaming-first, được hiển thị trong hình trên, giúp tách biệt các transactional workloads và analytical workloads.\nTransactional workloads – user account, organization settings, billing, và các khối lượng công việc tương tự chạy trên Amazon RDS for PostgreSQL. Analytical workloads – các telemetry events, metrics, query logs, và request traces được xử lý bởi ClickHouse Cloud. Các thành phần chính Các thành phần của giải pháp bao gồm:\nIngestion layer Amazon API Gateway nhận telemetry từ các agents của Laravel được nhúng trong ứng dụng của khách hàng. Lambda xác thực và bổ sung thông tin cho events. Các events đã được xác thực và bổ sung thông tin được publish đến Amazon MSK, được phân vùng để có khả năng mở rộng. Streaming to analytics ClickPipes trong ClickHouse Cloud đăng ký trực tiếp vào các topics của MSK, giảm nhu cầu xây dựng và quản lý các extract, transform, and load (ETL) pipelines. Materialized views trong ClickHouse tiền tổng hợp và chuyển đổi raw JSON thành dạng query-ready. Dashboards và delivery Nightwatch dashboard, được xây dựng với Laravel, Inertia, và React, chạy trên AWS Fargate for Amazon ECS. Amazon ElastiCache for Redis tăng tốc sessions và cache lookups. Cloudflare CDN cung cấp low-latency delivery đến người dùng toàn cầu. Tại sao lại là Amazon MSK và ClickHouse Cloud? Nightwatch đòi hỏi một streaming backbone bền bỉ, có khả năng mở rộng theo chiều ngang và ít phải bảo trì.\nVới Amazon MSK Express brokers, chúng tôi đã đạt được hơn một tỷ events mỗi giây trong quá trình load testing, hưởng lợi từ low-latency, elastic scaling, và simplified operations. MSK Express brokers không yêu cầu storage sizing hoặc provisioning, mở rộng nhanh hơn gấp 20 lần, và phục hồi nhanh hơn 90% so với các Apache Kafka brokers tiêu chuẩn - tất cả trong khi vẫn thực thi best-practice defaults và client quotas để có hiệu suất đáng tin cậy. Sự tích hợp liền mạch của nó với các dịch vụ AWS khác-như Lambda, Amazon Simple Storage Service (Amazon S3), và Amazon CloudWatch-đã giúp việc xây dựng một resilient, end-to-end streaming architecture trở nên đơn giản.\nĐể tiếp nhận và chuyển đổi các events này trong thời gian thực, Nightwatch sử dụng ClickHouse Cloud và nền tảng tích hợp được quản lý của nó, ClickPipes. ClickHouse Cloud vượt trội trong các analytical workloads bằng cách cung cấp hiệu suất truy vấn cho phân tích nhanh hơn tới 100 lần so với các row-based databases truyền thống. Các thuật toán nén tiên tiến của nó giúp tiết kiệm tới 90% dung lượng lưu trữ, giảm đáng kể chi phí cơ sở hạ tầng trong khi vẫn duy trì hiệu suất cao. Với columnar architecture và execution engine được tối ưu hóa, ClickHouse Cloud có thể truy vấn hàng tỷ hàng trong vòng chưa đầy 1 giây, cho phép Laravel Nightwatch phục vụ các real-time dashboards và analytics ở quy mô toàn cầu.\nBằng cách tích hợp Amazon MSK và ClickHouse bằng ClickPipes, Laravel cũng đã giảm bớt gánh nặng vận hành của việc xây dựng và quản lý các ETL pipelines, giảm độ trễ và sự phức tạp.\nVượt qua thách thức Sự phức tạp trong kiểm thử Trong khi việc đo lường hiệu năng tổng hợp và các bộ dữ liệu thử nghiệm mang lại kết quả hữu ích, cần có một khối lượng công việc thực tế hơn để kiểm tra nghiêm ngặt cơ sở hạ tầng và mã nguồn trước khi triển khai lên sản phẩm. Nhóm đã sử dụng Terraform để quản lý cơ sở hạ tầng cùng với application code, tạo ra nhiều môi trường dev và test, và cho phép họ kiểm tra nền tảng nội bộ với các ứng dụng của chính mình trước mỗi lần phát hành.\nCơ sở hạ tầng đa khu vực Nhu cầu phục vụ nhiều khu vực lưu trữ dữ liệu cũng mang lại những thách thức—với độ trễ, sự phức tạp và chi phí là những mối quan tâm hàng đầu. Tuy nhiên, AWS, ClickHouse Cloud, và Cloudflare stack đã cung cấp một bộ công cụ mạng và các tùy chọn mở rộng mạnh mẽ. Trong khi VPC peering, RDS replication, và global server load balancing đảm nhận phần việc nặng về mạng, khả năng mở rộng và điều chỉnh kích thước phù hợp cho từng tài nguyên đã giúp giữ chi phí ở mức tối thiểu.\nHiệu suất truy vấn ở quy mô lớn Materialized views, phân vùng chuỗi thời gian thông minh, và các codecs chuyên dụng của ClickHouse đã giúp đảm bảo rằng các truy vấn vẫn dưới một giây ngay cả khi khối lượng dữ liệu tăng lên hàng tỷ. Trong khi đó, việc tách biệt tính toán cho phép các khối lượng công việc riêng biệt mở rộng độc lập trong khi truy cập cùng một dữ liệu, với các cụm được điều chỉnh kích thước phù hợp theo chiều ngang và chiều dọc tùy thuộc vào yêu cầu của mỗi tải.\nKết quả Việc ra mắt Laravel Nightwatch đã vượt qua mong đợi:\n5,300 người dùng đăng ký trong 24 giờ đầu tiên 500 triệu events được xử lý trong ngày đầu tiên 97 ms độ trễ trung bình của dashboard request 760,000 exceptions được ghi lại và phân tích trong thời gian thực Bằng cách xây dựng trên Amazon MSK và ClickHouse Cloud, chúng tôi đã có khả năng mở rộng từ con số không lên đến hàng tỷ events mà không phải hy sinh hiệu suất hay trải nghiệm nhà phát triển.\nTiếp theo là gì Laravel có kế hoạch mở rộng Nightwatch với:\nNhiều khu vực hơn để phục vụ khách hàng có yêu cầu về data sovereignty ngoài US và EU. Thu thập dữ liệu rộng hơn để cung cấp cái nhìn sâu sắc hơn nữa vào customer’s applications. Chứng nhận SOC 2 để phục vụ khách hàng có yêu cầu tuân thủ chặt chẽ hơn. Giám sát và phân tích nâng cao hơn để xác định các vấn đề trước khi chúng ảnh hưởng người dùng. Kiến trúc hiện tại hỗ trợ các ứng dụng ở mọi quy mô, từ sở thích cá nhân đến doanh nghiệp (bao gồm cả free tier), và được thiết kế để xử lý hơn một nghìn tỷ events hàng tháng mà không làm giảm hiệu suất.\nKết luận Laravel Nightwatch chứng minh cách Amazon MSK, ClickHouse Cloud, và các công nghệ AWS serverless có thể kết hợp để tạo một nền tảng giám sát thời gian thực, hiệu quả về chi phí ở quy mô toàn cầu. Bằng cách thiết kế cho quy mô lớn từ ngày đầu, Laravel đã cung cấp các phân tích dưới một giây trên hàng tỷ events, trong khi vẫn duy trì trải nghiệm thân thiện với nhà phát triển mà cộng đồng của họ mong đợi.\nVề các tác giả Jess Archer là Engineering Manager và Head of Nightwatch tại Laravel, tập trung vào application observability, performance monitoring, và trải nghiệm nhà phát triển. Cô lãnh đạo nhóm Nightwatch trong khi vẫn trực tiếp tham gia vào codebase. Trước Laravel, Jess đã làm việc trên các nền tảng thu thập dữ liệu lâm sàng, phần mềm cho cơ quan thực thi pháp luật, và các giải pháp chống lừa đảo trong ngành ngân hàng. Sau đó, cô đã đóng góp rộng rãi cho hệ sinh thái open-source của Laravel trước khi chuyển sang vai trò lãnh đạo hiện tại. Jess rất đam mê open source và tạo ra các công cụ giúp các nhà phát triển làm việc hiệu quả hơn.\nJames Carpenter là Senior Infrastructure Engineer gia nhập Laravel vào năm 2024 với tư cách là Infrastructure Lead cho nhóm Nightwatch, mang theo kinh nghiệm từ 15 năm trong lĩnh vực thể thao và chăm sóc sức khỏe. Chuyên về DevOps và Infrastructure, anh đam mê giải quyết các vấn đề phức tạp và tạo ra những trải nghiệm đặc biệt cho cả khách hàng và nhà phát triển.\nJohnny Mirza là Solution Architect tại ClickHouse, làm việc với người dùng trên khắp khu vực APAC. Với hơn 20 năm kinh nghiệm trong lĩnh vực solutions engineering, anh có kinh nghiệm trong việc kiến trúc và triển khai các giải pháp cho các khách hàng doanh nghiệp trong các lĩnh vực viễn thông, truyền thông, bảo hiểm và dịch vụ tài chính. Johnny có chuyên môn cao về tích hợp giữa cơ sở hạ tầng public cloud và on-premise, đồng thời tập trung vào đảm bảo dịch vụ, nền tảng giám sát và các công nghệ open-source. Trước ClickHouse, Johnny đã là thành viên của các nhóm kỹ thuật giải pháp tại Confluent, Splunk, và Optus.\nMasudur Rahaman Sayem là Streaming Data Architect tại AWS với hơn 25 năm kinh nghiệm trong ngành IT. Anh hợp tác với các khách hàng của AWS trên toàn thế giới để kiến trúc và triển khai các giải pháp data streaming phức tạp nhằm giải quyết các thách thức kinh doanh phức tạp. Là một chuyên gia về distributed computing, Sayem chuyên thiết kế kiến trúc hệ thống phân tán quy mô lớn để đạt hiệu suất và khả năng mở rộng tối đa. Anh có sự quan tâm và đam mê sâu sắc đối với kiến trúc phân tán, điều mà anh áp dụng để thiết kế các giải pháp cấp doanh nghiệp ở quy mô internet.\n"
},
{
	"uri": "http://localhost:1313/fcj-workshop/vi/3-blogstranslated/3.3-blog3/",
	"title": "Blog 3",
	"tags": [],
	"description": "",
	"content": "Cách xuất dữ liệu ra Amazon S3 Tables bằng AWS Step Function Distributed Map bởi Chetan Makvana và Aidan Eglin | vào ngày 01 THÁNG 10 NĂM 2025 | trong mục Advanced (300), Amazon S3 Tables, AWS Step Functions, Serverless, Technical How-to\nCác công ty chạy các serverless workloads thường cần thực hiện các hoạt động extract, transform, and load (ETL) trên các tệp dữ liệu được lưu trữ trong các bucket của Amazon Simple Storage Service (Amazon S3). Mặc dù các phương pháp truyền thống như AWS Lambda trigger for Amazon S3 hoặc Amazon S3 Event Notifications có thể xử lý các hoạt động này, chúng có thể không đáp ứng đủ khi các luồng công việc đòi hỏi khả năng hiển thị, kiểm soát nâng cao hoặc sự can thiệp của con người. Ví dụ, một số quy trình có thể cần xem xét thủ công các bản ghi bị lỗi hoặc phê duyệt rõ ràng trước khi chuyển sang các giai đoạn tiếp theo. Các giải pháp tự xây dựng của khách hàng cho những vấn đề này có thể phức tạp và dễ bị lỗi.\nAWS Step Functions giải quyết những thách thức này bằng cách cung cấp các khả năng quản lý và giám sát luồng công việc được tích hợp sẵn. Tính năng Step Functions Distributed Map được thiết kế cho các luồng công việc xử lý dữ liệu song song, high-throughput để các công ty có thể xử lý các công việc ETL phức tạp, fan-out processing, và trực quan hóa dữ liệu ở quy mô lớn. Distributed Map xử lý mỗi mục trong bộ dữ liệu như một child workflow độc lập, xử lý hàng triệu bản ghi trong khi vẫn duy trì các cơ chế kiểm soát đồng thời, khả năng chịu lỗi, và theo dõi tiến trình được tích hợp sẵn. Dữ liệu đã xử lý có thể được xuất liền mạch đến nhiều đích khác nhau, bao gồm cả Amazon S3 Tables với sự hỗ trợ của Apache Iceberg.\nTrong bài viết này, chúng tôi chỉ ra cách dùng Step Functions Distributed Map để xử lý các Amazon S3 objects và xuất kết quả ra Amazon S3 Tables, tạo một data processing pipeline có khả năng mở rộng và dễ bảo trì.\nXem GitHub repository đi kèm để biết hướng dẫn chi tiết về việc triển khai giải pháp này cũng như mã nguồn mẫu.\nTổng quan giải pháp Hãy xem xét một công ty điện tử tiêu dùng thường xuyên tham gia các triển lãm thương mại và hội nghị ngành. Trong các sự kiện này, những người tham dự quan tâm sẽ điền vào các biểu mẫu đăng ký bằng giấy để yêu cầu demo sản phẩm, nhận bản tin, hoặc tham gia các chương trình truy cập sớm. Sau sự kiện, đội ngũ của công ty quét hàng trăm nghìn biểu mẫu này và tải chúng lên Amazon S3. Thay vì xem xét thủ công từng biểu mẫu, công ty muốn tự động hóa việc trích xuất các chi tiết chính của khách hàng như tên, địa chỉ email, địa chỉ gửi thư, và lĩnh vực quan tâm. Họ muốn lưu trữ dữ liệu có cấu trúc này trong S3 Tables với định dạng Apache Iceberg để phục vụ cho việc phân tích và nhắm mục tiêu các chiến dịch marketing ở các công đoạn sau.\nHãy xem cách giải pháp trong bài viết này sử dụng Distributed Map để xử lý các tệp PDF song song, trích xuất dữ liệu bằng Amazon Textract, và ghi trực tiếp đầu ra đã được làm sạch vào S3 Tables. Kết quả là một quy trình tiếp nhận dữ liệu sau sự kiện có khả năng mở rộng và hoàn toàn serverless, như được hiển thị trong hình sau.\nLuồng công việc xử lý dữ liệu như được hiển thị trong sơ đồ trên bao gồm các bước sau:\nNgười dùng tải các biểu mẫu quan tâm của khách hàng dưới dạng tệp PDF đã quét vào một bucket Amazon S3. Một quy tắc Amazon EventBridge Scheduler được kích hoạt theo các khoảng thời gian đều đặn, khởi tạo một Step Functions workflow. Lần thực thi workflow này sẽ kích hoạt một trạng thái Step Functions Distributed Map, liệt kê tất cả các tệp PDF đã được tải lên Amazon S3 kể từ lần chạy trước. Distributed Map duyệt qua danh sách các đối tượng và chuyển mỗi object’s metadata (bucket, key, size, entity tag [ETag]) cho một lần thực thi child workflow. Đối với mỗi object, child workflow gọi Amazon Textract với bucket và key được cung cấp để trích xuất raw text và các trường liên quan (tên, địa chỉ email, địa chỉ gửi thư, lĩnh vực quan tâm) từ tệp PDF. Child workflow gửi dữ liệu đã trích xuất đến Amazon Data Firehose, được cấu hình để chuyển tiếp dữ liệu đến S3 Tables. Firehose gom nhóm dữ liệu đến từ child workflow và ghi nó vào S3 Tables theo một khoảng thời gian được định cấu hình sẵn mà bạn chọn. Với dữ liệu hiện đã có cấu trúc và có thể truy cập trong S3 Tables, người dùng có thể dễ dàng phân tích chúng bằng các truy vấn SQL tiêu chuẩn với Amazon Athena hoặc các công cụ business intelligence như Amazon QuickSight.\nLuồng công việc xử lý dữ liệu EventBridge Scheduler khởi động các Step Functions workflows mới theo các khoảng thời gian đều đặn. Mốc thời gian cho lịch trình này là linh hoạt. Tuy nhiên, khi thiết lập lịch trình của bạn, hãy đảm bảo tần suất phù hợp với khoảng thời gian mà state machine của bạn được cấu hình để tìm kiếm các tệp PDF. Ví dụ, nếu state machine của bạn kiểm tra các tệp PDF từ tuần trước, bạn sẽ muốn lên lịch cho nó chạy hàng tuần. Step Functions workflow sau đó thực hiện ba bước sau (lưu ý rằng đây là các bước 4, 5, 6, và 7 trong sơ đồ luồng công việc ở trên):\nTrích xuất dữ liệu người dùng liên quan từ các tệp PDF. Gửi dữ liệu người dùng đã trích xuất đến Firehose. Ghi dữ liệu vào S3 Tables ở định dạng bảng Apache Iceberg. Sơ đồ sau minh họa luồng công việc này.\nHãy xem xét chi tiết hơn từng bước của luồng công việc trên.\nTrích xuất dữ liệu người dùng liên quan từ tài liệu PDF Step Functions sử dụng Distributed Map để xử lý các tệp PDF đồng thời trong các child workflows song song. Nó chấp nhận đầu vào từ các tệp JSON, JSONL, CSV, Parquet, các tệp Amazon S3 manifest được lưu trữ trong Amazon S3 (dùng để chỉ định các tệp cụ thể cần xử lý), hoặc một Amazon S3 bucket prefix (cho phép duyệt qua metadata của tất cả các đối tượng dưới tiền tố đó). Step Functions tự động xử lý việc song song hóa bằng cách chia nhỏ bộ dữ liệu và chạy các child workflows cho mỗi mục, với trường ItemBatcher cho phép nhóm nhiều tệp PDF vào một lần thực thi child workflow duy nhất (ví dụ: 10 tệp PDF mỗi batch) để tối ưu hóa hiệu suất và chi phí.\nẢnh chụp màn hình sau từ Step Functions console cho thấy cấu hình cho Distributed Map. Ví dụ, chúng tôi đã cấu hình Distributed Map để xử lý 10 tệp PDF quan tâm của khách hàng trong một child workflow duy nhất.\nHình ảnh sau đây cho thấy một ví dụ về các tệp PDF được quét này, bao gồm thông tin khách hàng mà giải pháp của bài viết này xử lý.\nMỗi child workflow sau đó gọi Amazon Textract AnalyzeDocument API với các truy vấn cụ thể để trích xuất thông tin khách hàng.\n{ \u0026#34;Document\u0026#34;: { \u0026#34;S3Object\u0026#34;: { \u0026#34;Bucket\u0026#34;: \u0026#34;\u0026lt;input PDFs bucket\u0026gt;\u0026#34;, \u0026#34;Name\u0026#34;: \u0026#34;{% $states.input.Key %}\u0026#34; } }, \u0026#34;FeatureTypes\u0026#34;: [ \u0026#34;QUERIES\u0026#34; ], \u0026#34;QueriesConfig\u0026#34;: { \u0026#34;Queries\u0026#34;: [ { \u0026#34;Alias\u0026#34;: \u0026#34;full_name\u0026#34;, \u0026#34;Text\u0026#34;: \u0026#34;What is the customer\u0026#39;s name?\u0026#34; }, { \u0026#34;Alias\u0026#34;: \u0026#34;phone_number\u0026#34;, \u0026#34;Text\u0026#34;: \u0026#34;What is the customer’s phone number?\u0026#34; }, { \u0026#34;Alias\u0026#34;: \u0026#34;mailing_address\u0026#34;, \u0026#34;Text\u0026#34;: \u0026#34;What is the customer’s mailing address?\u0026#34; }, { \u0026#34;Alias\u0026#34;: \u0026#34;interest\u0026#34;, \u0026#34;Text\u0026#34;: \u0026#34;What is the customer’s interest?\u0026#34; } ] } } API phân tích mỗi tệp PDF được quét và trả về một cấu trúc JSON chứa thông tin khách hàng đã được trích xuất.\nGửi dữ liệu người dùng đã trích xuất đến Firehose Child workflow sau đó sử dụng một Firehose PutRecordBatch API action với service integrations để đưa thông tin khách hàng đã trích xuất vào hàng đợi để xử lý thêm. Yêu cầu hành động PutRecordBatch bao gồm tên luồng Firehose và các bản ghi dữ liệu. Các bản ghi dữ liệu bao gồm một blob dữ liệu từ bước 1 chứa thông tin khách hàng đã trích xuất, như trong ví dụ sau.\n{ \u0026#34;DeliveryStreamName\u0026#34;: \u0026#34;put_raw_form_data_100\u0026#34;, \u0026#34;Records\u0026#34;: [ { \u0026#34;Data\u0026#34;: \u0026#34;{\\\u0026#34;full_name\\\u0026#34;:\\\u0026#34;Anthony Ayala\\\u0026#34;,\\\u0026#34;phone_number\\\u0026#34;:\\\u0026#34;001-384-925-0701\\\u0026#34;,\\\u0026#34;mailing_address\\\u0026#34;:\\\u0026#34;38548 Joshua Wall Suite 974, East Heatherfort, OH 32669\\\u0026#34;,\\\u0026#34;interest\\\u0026#34;:\\\u0026#34;Fitness Trackers\\\u0026#34;,\\\u0026#34;processed_date\\\u0026#34;:\\\u0026#34;2025-05-01\\\u0026#34;}\u0026#34; }, { \u0026#34;Data\u0026#34;: \u0026#34;{\\\u0026#34;full_name\\\u0026#34;:\\\u0026#34;Becky Williams\\\u0026#34;,\\\u0026#34;phone_number\\\u0026#34;:\\\u0026#34;+1-283-499-2466\\\u0026#34;,\\\u0026#34;mailing_address\\\u0026#34;:\\\u0026#34;227 King Forge Suite 241, East Nathanland, PR 05687\\\u0026#34;,\\\u0026#34;interest\\\u0026#34;:\\\u0026#34;Al Assistants\\\u0026#34;,\\\u0026#34;processed_date\\\u0026#34;:\\\u0026#34;2025-05-01\\\u0026#34;}\u0026#34; } ] } Ghi dữ liệu vào S3 Tables ở định dạng bảng Apache Iceberg Firehose quản lý hiệu quả việc data buffering, chuyển đổi định dạng, và phân phối đáng tin cậy đến nhiều đích khác nhau, bao gồm Apache Iceberg, raw files trong Amazon S3, Amazon OpenSearch Service, hoặc any of the other supported destinations. Các bảng Apache Iceberg có thể được tự quản lý trong Amazon S3 hoặc được lưu trữ trong S3 Tables. Mặc dù các bảng Iceberg tự quản lý đòi hỏi tối ưu hóa thủ công—chẳng hạn như compaction và snapshot expiration—S3 Tables tự động tối ưu hóa lưu trữ cho các khối lượng công việc phân tích quy mô lớn, cải thiện hiệu suất truy vấn và giảm chi phí lưu trữ.\nFirehose đơn giản hóa quá trình streaming dữ liệu bằng cách cấu hình một luồng phân phối, chọn một nguồn dữ liệu, và đặt một bảng Iceberg làm đích. Sau khi bạn đã thiết lập xong, luồng Firehose đã sẵn sàng để phân phối dữ liệu. Dữ liệu được phân phối có thể được truy vấn từ S3 Tables bằng cách sử dụng Athena, như được hiển thị trong ảnh chụp màn hình sau của giao diện điều khiển Athena.\nKết quả truy vấn bao gồm tất cả dữ liệu khách hàng đã được xử lý từ các tệp PDF, như được hiển thị trong ảnh chụp màn hình sau.\nSự tích hợp này thể hiện một giải pháp mạnh mẽ, không cần mã nguồn để chuyển đổi các biểu mẫu raw PDF thành dữ liệu được làm giàu, có thể truy vấn trong một bảng Iceberg. Bạn có thể sử dụng những dữ liệu này để phân tích sâu hơn.\nKết luận Trong bài viết này, chúng tôi đã chỉ ra cách xây dựng một giải pháp serverless, có khả năng mở rộng để xử lý tài liệu PDF và xuất dữ liệu đã trích xuất ra S3 Tables bằng cách sử dụng Step Functions Distributed Map. Kiến trúc này mang lại một số lợi ích chính như độ tin cậy, hiệu quả về chi phí, khả năng hiển thị, và khả năng bảo trì. Bằng cách tận dụng các dịch vụ của AWS như Step Functions, Amazon Textract, Firehose, và S3 Tables, các công ty có thể tự động hóa các luồng công việc xử lý tài liệu của mình đồng thời đảm bảo hiệu suất tối ưu và hoạt động xuất sắc. Giải pháp này có thể được điều chỉnh cho nhiều trường hợp sử dụng khác ngoài các biểu mẫu quan tâm của khách hàng, chẳng hạn như xử lý hóa đơn, biểu mẫu ứng tuyển, hoặc bất kỳ kịch bản nào đòi hỏi trích xuất dữ liệu có cấu trúc từ tài liệu ở quy mô lớn.\nMặc dù ví dụ này tập trung vào việc xử lý dữ liệu PDF và ghi vào S3 Tables, Distributed Map có thể xử lý nhiều nguồn đầu vào khác nhau bao gồm các tệp JSON, JSONL, CSV, và Parquet trong Amazon S3; các mục trong bảng Amazon DynamoDB; kết quả truy vấn Athena; và tất cả các API List của AWS có phân trang. Tương tự, thông qua Step Functions service integrations, bạn có thể ghi kết quả ra nhiều đích đến như các bảng DynamoDB tables bằng cách sử dụng tích hợp dịch vụ PutItem.\nĐể bắt đầu với giải pháp này, hãy xem GitHub repository đi kèm để biết hướng dẫn triển khai và mã nguồn mẫu.\n"
},
{
	"uri": "http://localhost:1313/fcj-workshop/vi/4-eventparticipated/4.1-event1/",
	"title": "Event 1",
	"tags": [],
	"description": "",
	"content": "Báo cáo tổng hợp: \u0026ldquo;Vietnam Cloud Day HCMC Connect Edition: GenAI \u0026amp; Data Track\u0026rdquo; Mục tiêu sự kiện Cập nhật các xu hướng công nghệ mới nhất về Generative AI (GenAI) và Phân tích dữ liệu (Data Analytics). Khám phá cách xây dựng nền tảng dữ liệu thống nhất (Unified Data Foundation) để hỗ trợ các ứng dụng AI. Tìm hiểu các giải pháp thực tế từ các doanh nghiệp hàng đầu trong việc áp dụng GenAI vào quy trình vận hành. Kết nối với các chuyên gia và lãnh đạo công nghệ để trao đổi về chiến lược chuyển đổi số. Diễn giả Eric Yeo - Country General Manager, AWS Vietnam Trung Tri Nguyen - Analytics Specialist Solutions Architect, AWS Hailey Dinh - Senior Sales Specialist (ASEAN Data \u0026amp; AI), AWS Quang Chu - Senior Solutions Architect, AWS Vietnam Christopher Bennett - CTO, TymeX Điểm nổi bật (Key Highlights) Nền tảng dữ liệu thống nhất (Unified Data Foundation) Tầm quan trọng của việc phá vỡ các \u0026ldquo;silos\u0026rdquo; dữ liệu (kho dữ liệu cô lập) để tạo ra một nguồn chân lý duy nhất (single source of truth). Sử dụng các dịch vụ như Amazon S3, AWS Glue, và AWS Lake Formation để xây dựng Data Lakehouse bảo mật và có khả năng mở rộng. Tích hợp dữ liệu liền mạch giữa phân tích (Analytics) và AI/ML để tăng tốc độ đổi mới. Ứng dụng Generative AI với Amazon Bedrock Cách đơn giản hóa việc xây dựng và mở rộng các ứng dụng GenAI bằng Amazon Bedrock. Tận dụng các mô hình nền tảng (Foundation Models) hàng đầu thông qua API duy nhất mà không cần quản lý cơ sở hạ tầng phức tạp. Các tính năng bảo mật và quyền riêng tư dữ liệu khi triển khai GenAI cho doanh nghiệp. Chuyển đổi số trong lĩnh vực Tài chính (Use Case: TymeX) Chia sẻ thực tế về việc xây dựng giải pháp cho vay cá nhân hóa từ đầu đến cuối (end-to-end personalized lending solution). Áp dụng phân tích dữ liệu nâng cao để đánh giá rủi ro và tối ưu hóa trải nghiệm khách hàng. Bài học chính (Key Takeaways) Chiến lược dữ liệu hiện đại (Modern Data Strategy) Dữ liệu là nhiên liệu cho AI: Để GenAI hoạt động hiệu quả, doanh nghiệp cần có một chiến lược dữ liệu vững chắc, đảm bảo chất lượng, tính sẵn sàng và tuân thủ bảo mật. Zero-ETL: Xu hướng tích hợp trực tiếp giữa các dịch vụ cơ sở dữ liệu (như Amazon Aurora, DynamoDB) và kho dữ liệu (Amazon Redshift) để giảm thiểu việc di chuyển dữ liệu thủ công. Quyền năng của Generative AI GenAI không chỉ là trào lưu mà đang tạo ra tác động thực tế đến nền kinh tế và năng suất lao động. Các ứng dụng tiềm năng: Tự động hóa chăm sóc khách hàng, tạo nội dung marketing, hỗ trợ lập trình (coding assistant), và phân tích dữ liệu thông minh. Kiến trúc Serverless cho Data \u0026amp; AI Sử dụng kiến trúc không máy chủ (Serverless) giúp giảm gánh nặng vận hành, cho phép đội ngũ tập trung vào việc phát triển logic nghiệp vụ và mô hình AI. Áp dụng vào công việc Rà soát lại kiến trúc dữ liệu: Đánh giá lại cách tổ chức dữ liệu hiện tại của dự án, xem xét áp dụng mô hình Data Lakehouse. Thử nghiệm Amazon Bedrock: Đề xuất xây dựng các bản thử nghiệm (POC) nhỏ sử dụng Bedrock để giải quyết các bài toán cụ thể (ví dụ: tóm tắt văn bản, chatbot nội bộ). Tối ưu hóa quy trình ETL: Nghiên cứu các giải pháp Zero-ETL của AWS để giảm độ trễ dữ liệu. Trải nghiệm sự kiện Tham gia Vietnam Cloud Day HCMC Connect Edition (Track GenAI \u0026amp; Data) mang lại cho tôi cái nhìn sâu sắc về tương lai của công nghệ dữ liệu và AI.\nHọc hỏi từ các Case Study thực tế Phần chia sẻ của TymeX và các đối tác giúp tôi hình dung rõ ràng hơn về những thách thức và giải pháp khi triển khai AI trong môi trường doanh nghiệp lớn, đặc biệt là ngành tài chính đòi hỏi độ chính xác cao. Khám phá hệ sinh thái AWS cho Data \u0026amp; AI Hiểu rõ hơn về sự liên kết chặt chẽ giữa các dịch vụ AWS. Không có một dịch vụ nào đứng riêng lẻ; sức mạnh nằm ở sự kết hợp giữa Data Analytics (Glue, Redshift) và AI (SageMaker, Bedrock). Kết nối cộng đồng Sự kiện là cơ hội tuyệt vời để gặp gỡ các chuyên gia trong ngành, trao đổi về những khó khăn chung khi làm việc với dữ liệu lớn và nhận được những lời khuyên giá trị. Một số hình ảnh tại sự kiện Nhìn chung, track về GenAI và Data đã củng cố niềm tin của tôi rằng \u0026ldquo;Dữ liệu là tài sản cốt lõi\u0026rdquo;. Việc nắm vững cách quản lý dữ liệu và ứng dụng AI sẽ là chìa khóa để tạo ra lợi thế cạnh tranh trong thời đại số.\n"
},
{
	"uri": "http://localhost:1313/fcj-workshop/vi/1-worklog/",
	"title": "Nhật ký công việc",
	"tags": [],
	"description": "",
	"content": "Trong trang này bạn sẽ cần giới thiệu worklog của bạn như thế nào? Bạn hoàn thành chương trình trong vòng bao nhiêu tuần? Bạn đã làm gì trong các tuần đó?\nThông thường và cũng là tiêu chuẩn, một worklog được thực hiện trong khoảng 3 tháng (trong suốt thời gian thực tập) với nội dung các tuần như sau:\nTuần 1: Làm quen với AWS và các dịch vụ cơ bản trong AWS\nTuần 2: Làm công việc A\u0026hellip;\nTuần 3: Làm công việc B\u0026hellip;\nTuần 4: Làm công việc C\u0026hellip;\nTuần 5: Làm công việc D\u0026hellip;\nTuần 6: Làm công việc E\u0026hellip;\nTuần 7: Làm công việc G\u0026hellip;\nTuần 8: Làm công việc H\u0026hellip;\nTuần 9: Làm công việc I\u0026hellip;\nTuần 10: Làm công việc L\u0026hellip;\nTuần 11: Làm công việc M\u0026hellip;\nTuần 12: Làm công việc N\u0026hellip;\nTuần 13: Làm công việc O\u0026hellip;\n"
},
{
	"uri": "http://localhost:1313/fcj-workshop/vi/1-worklog/1.1-week1/",
	"title": "Worklog Tuần 1",
	"tags": [],
	"description": "",
	"content": "Mục tiêu tuần 1: Kết nối, làm quen với các thành viên trong First Cloud Journey. Hiểu dịch vụ AWS cơ bản, cách dùng console \u0026amp; CLI. Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Làm quen với các thành viên FCJ - Đọc và lưu ý các nội quy, quy định tại đơn vị thực tập - Tạo tài khoản AWS Free Tier account 08/09/2025 08/09/2025 https://000001.awsstudygroup.com/ 3 - Tìm hiểu AWS và các loại dịch vụ + Compute + Storage + Networking + Database + \u0026hellip; -Thực hành: + Tạo bảo mật tài khoản AWS bằng MFA +Tạo budget cho tài khoản AWS 09/09/2025 09/09/2025 https://000007.awsstudygroup.com/ 4 - Tìm hiểu về Amazon VPC + Tìm hiểu về Sercutity Group, Direct Connect, Load Balancer, Extra Resources - Thực hành: + Tạo VPC, Subnet, Internet Gateway, Route table, Security Group + Kích hoạt VPC flow logs 10/09/2025 10/09/2025 https://000003.awsstudygroup.com/ 5 - Tìm hiểu EC2 cơ bản: + Instance types + AMI + EBS - Các cách remote SSH vào EC2 - Tìm hiểu Elastic IP - Thực hành: + Tạo EC2 server + Kiểm tra kết nối EC2 + Tạo Nat Gateway 11/09/2025 11/09/2025 https://000003.awsstudygroup.com/vi/4-createec2server/ 6 - Ôn lại kiến thức về EC2, VPC, dịch vụ của AWS - Học cách vẽ kiến trúc AWS -Thực hành: + Vẽ kiến trúc AWS trên draw.io 12/09/2025 12/09/2025 https://www.youtube.com/watch?v=l8isyDe-GwY\u0026list=PLahN4TLWtox2a3vElknwzU_urND8hLn1i\u0026index=2 Kết quả đạt được tuần 1: Hiểu AWS là gì và nắm được các nhóm dịch vụ cơ bản:\nCompute Storage Networking Database \u0026hellip; Đã tạo và cấu hình AWS Free Tier account thành công.\nLàm quen với AWS Management Console và biết cách tìm, truy cập, sử dụng dịch vụ từ giao diện web.\nCài đặt và cấu hình AWS CLI trên máy tính bao gồm:\nAccess Key Secret Key Region mặc định \u0026hellip; Sử dụng AWS CLI để thực hiện các thao tác cơ bản như:\nKiểm tra thông tin tài khoản \u0026amp; cấu hình Lấy danh sách region Xem dịch vụ EC2 Tạo và quản lý key pair Kiểm tra thông tin dịch vụ đang chạy \u0026hellip; Có khả năng kết nối giữa giao diện web và CLI để quản lý tài nguyên AWS song song.\n\u0026hellip;\n"
},
{
	"uri": "http://localhost:1313/fcj-workshop/vi/1-worklog/1.2-week2/",
	"title": "Worklog Tuần 2",
	"tags": [],
	"description": "",
	"content": "Mục tiêu tuần 2: Hiểu về EC2, CloudFormation, VPC peering, AWS Transit Gateway. Biết cách khởi chạy Amazon Linux Instance và Microsoft Windows Instance. Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Thực hành: + Tạo VPC cho Linux và Windows + Tạo Security Group (SC) cho Linux và Windows Instance + Khởi chạy Linux và Windows Instance + Kết nối tới Linux và Windows Instance + Triển khai ứng dụng quản lý người dùng AWS trên Amazon EC2 Linux/Windows 15/09/2025 15/09/2025 https://000004.awsstudygroup.com/ 3 - Tìm hiểu về Hybrid DNS với Route 53: + Outbound Endpoints + Inbound Endpoints + Route 53 Resolver Rules - Thực hành: + Tạo key pair + Tạo CloudFormation Template, SC + Kết nối tới RDGW 16/09/2025 16/09/2025 https://000010.awsstudygroup.com/ 4 - Tìm hiểu về VPC peering - Thực hành: + Tạo VPC peering 17/09/2025 17/09/2025 https://000019.awsstudygroup.com/ 5 - Tham gia sự kiện AWS Cloud Day 18/09/2025 18/09/2025 6 - Tìm hiểu về AWS Transit Gateway Thực hành: + Tạo AWS Transit Gateway 19/09/2025 19/09/2025 https://000020.awsstudygroup.com/ Kết quả đạt được tuần 2: Hiểu EC2 là gì và nắm vững các kiến thức cơ bản về EC2:\nInstance Type AMI Key Pair Backup Khởi chạy thành công Instance từ custom AMI và truy cập vào Windows/Linux Instance khi mất key pair.\nTạo thành công Hybrid DNS với Route 53 Resolver , kết nối tới RDGW và thiết lập DNS:\nOutbound Endpoint Inbound Endpoint Route 53 Resolver Rules Hiểu về VPC Peering và thiết lập:\nCloudFormation Template Security Group EC2 Instance Network ACL Route Tables Cross-Peer DNS Hiểu về AWS Transit Gateway và biết cách tạo:\nTransit Gateway Transit Gateway Attachment Transit Gateway Route Tables Thêm các tuyến Transit Gateway vào VPC Route Tables "
},
{
	"uri": "http://localhost:1313/fcj-workshop/vi/1-worklog/1.3-week3/",
	"title": "Worklog Tuần 3",
	"tags": [],
	"description": "",
	"content": "Mục tiêu tuần 3: Hiểu về các dịch vụ EC2 và S3. Có thể import (nhập) máy ảo vào AWS. Có thể export (xuất) máy ảo từ EC2 instance và AMI. Có thể mount (gắn) file sharing lên máy on-premise (máy chủ tại chỗ). Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Tìm hiểu về EC2 cơ bản: + Loại Instance (Instance Type) + User data + Meta data + EC2 Auto Scaling + EFS/FSx + Lightsail + MGN 22/09/2025 22/09/2025 https://www.youtube.com/watch?v=e7XeKdOVq40\u0026list=PLahN4TLWtox2a3vElknwzU_urND8hLn1i\u0026index=73 3 - Thực hành: + Tạo S3 Bucket + Tải dữ liệu lên (Load data) + Triển khai web sử dụng S3 + Tăng tốc Static Web với CloudFront 23/09/2025 23/09/2025 https://000057.awsstudygroup.com/ 4 - Thực hành: + Tạo Storage Gateway [Image of AWS Storage Gateway architecture] + Tạo File Shares + Mount File Shares trên máy on-premises + Tạo backup plan (kế hoạch sao lưu) + Thiết lập thông báo (notifications) | 24/09/2025 | 24/09/2025 | https://000024.awsstudygroup.com/ https://000013.awsstudygroup.com/ | | 5 | - Tìm hiểu về S3: + Access Point + Storage class + Static Website \u0026amp; CORS + Glacier + Snow Family - Storage Gateway - Backup | 25/09/2025 | 25/09/2025 | https://www.youtube.com/watch?v=hsCfP0IxoaM\u0026list=PLahN4TLWtox2a3vElknwzU_urND8hLn1i\u0026index=103 | | 6 | - Thực hành: + Import máy ảo vào AWS + Triển khai Instance từ AMI + Export máy ảo từ EC2 instance và từ AMI thông qua S3 bucket | 26/09/2025 | 26/09/2025 | https://000014.awsstudygroup.com/ |\nKết quả đạt được tuần 3: Đã hiểu về EC2 và nắm vững nhóm dịch vụ cơ bản:\nUser/Meta data EC2 Auto Scaling EFS/FSx Lightsail MGN Đã hiểu S3 là gì và nắm vững:\nAccess point Storage class Static Website \u0026amp; CORS Glacier Đã tạo và cấu hình thành công Static Web bằng cách sử dụng S3.\nĐã import thành công máy ảo vào AWS.\nĐã export thành công EC2 Instance từ AWS/AMI.\nĐã mount thành công file sharing lên máy on-premise.\n"
},
{
	"uri": "http://localhost:1313/fcj-workshop/vi/1-worklog/1.4-week4/",
	"title": "Worklog Tuần 4",
	"tags": [],
	"description": "",
	"content": "Mục tiêu tuần 4: Hiểu những kiến thức cơ bản về bảo mật trên AWS. Biết cách quản lý tài nguyên bằng thẻ (tags). Biết cách tạo IAM role và policy. Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Thực hành: + Tạo CloudFormation + Tạo Amazon FSx (SSD \u0026amp; HDD) + Bật shadow copies, hạn ngạch lưu trữ người dùng và chia sẻ truy cập liên tục + Mở rộng dung lượng lưu trữ và thông lượng 29/09/2025 29/09/2025 https://000025.awsstudygroup.com/ 3 - Tìm hiểu về các dịch vụ bảo mật trên AWS: + Mô hình trách nhiệm chia sẻ (Shared Responsibility Model) + AWS Identity and Access Management (IAM) + Amazon Cognito + AWS Organization + KMS 30/09/2025 30/09/2025 https://www.youtube.com/watch?v=tsobAlSg19g\u0026list=PLahN4TLWtox2a3vElknwzU_urND8hLn1i\u0026index=150 4 - Thực hiện 3 bài lab 18, 22 và 27 - Thực hành: + Bật Security Hub + Tạo tags cho Instances + Tạo role cho Lambda function + Quản lý tài nguyên bằng cách sử dụng tags và resources groups 01/10/2025 01/10/2025 https://000022.awsstudygroup.com/ https://000027.awsstudygroup.com/ https://000018.awsstudygroup.com/ 5 - Thực hiện 3 bài lab 28, 30 và 33 - Thực hành: + Tạo IAM policy và role + Tạo Restriction Policy và IAM limited user + Tạo Key Management Service (KMS), AWS CloudTrail và Amazon Athena + Chia sẻ dữ liệu mã hóa trên S3 02/10/2025 02/10/2025 https://000028.awsstudygroup.com/ https://000030.awsstudygroup.com/ https://000033.awsstudygroup.com/ 6 - Thực hiện 2 bài lab 44 và 48 - Thực hành: + Tạo IAM Group, IAM User + Cấu hình điều kiện cho role (role condition) + Truy cập ứng dụng thông qua access key và IAM role trên EC2 03/10/2025 03/10/2025 https://000044.awsstudygroup.com/ https://000048.awsstudygroup.com/ Kết quả đạt được tuần 4: Đã hiểu về bảo mật trên AWS:\nMô hình trách nhiệm chia sẻ (Shared Responsibility Model) AWS Identity and Access Management (IAM) Amazon Cognito AWS Organization KMS Đã tạo và cấu hình thành công IAM role và policy.\nĐã làm quen với việc sử dụng tags và group resources để quản lý tài nguyên.\n"
},
{
	"uri": "http://localhost:1313/fcj-workshop/vi/1-worklog/1.5-week5/",
	"title": "Worklog Tuần 5",
	"tags": [],
	"description": "",
	"content": "Mục tiêu tuần 5: Ôn tập kiến thức về VPC, EC2, S3,\u0026hellip; Dịch 3 bài blog. Hiểu về thuật toán Minimax. Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Ôn tập kiến thức từ module 1 đến module 5 + VPC + EC2 + S3 + Security (Bảo mật) + \u0026hellip; 06/10/2025 06/10/2025 3 - Dịch 3 bài blog: + Rox tăng tốc năng suất bán hàng với các tác nhân AI được hỗ trợ bởi Amazon Bedrock + Cách Laravel Nightwatch xử lý hàng tỷ sự kiện quan sát trong thời gian thực với Amazon MSK và ClickHouse Cloud + Cách xuất dữ liệu sang Amazon S3 Tables bằng AWS Step Functions Distributed Map 07/10/2025 07/10/2025 4 - Ôn tập về React: + Component + Props + React hook - Tìm hiểu về thuật toán Minimax - Thực hành: + Tạo trò chơi Tic Tac Toe đơn giản 08/10/2025 08/10/2025 https://coderschool.notion.site/Naver-AI-Hackathon-Week-1-Web-Minimax-284ea86d567a80f98983c7c219c4308b 5 - Tạo trò chơi Tic Tac Toe cho phép người chơi đấu với AI với 2 chế độ: dễ và khó 09/10/2025 09/10/2025 https://coderschool.notion.site/Week-1-Assignment-React-27fea86d567a80718ce4ee04b19ed8d9 6 - Tiếp tục sửa lỗi và tối ưu hóa trò chơi Tic Tac Toe - Chỉnh sửa các bài blog 10/10/2025 10/10/2025 https://github.com/Son2110/tic-tac-toe-ai Kết quả đạt được tuần 5: Đã ôn tập kiến thức về VPC, EC2, S3, Bảo mật,\u0026hellip;\nHoàn thành việc dịch 3 bài blog.\nHiểu rõ về thuật toán Minimax.\nĐã tạo thành công ứng dụng Tic Tac Toe cho người chơi đấu với AI (2 chế độ dễ/khó) dựa trên thuật toán Minimax.\n"
},
{
	"uri": "http://localhost:1313/fcj-workshop/vi/1-worklog/1.6-week6/",
	"title": "Worklog Tuần 6",
	"tags": [],
	"description": "",
	"content": "Mục tiêu tuần 6: Hiểu về khái niệm cơ sở dữ liệu trên AWS. Biết cách tạo DB và kết nối DB với EC2. Hoàn thành bài tập của Hackathon. Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Tìm hiểu về cơ sở dữ liệu trên AWS: + Amazon RDS + Amazon Aurora + Amazon Redshift + Amazon Elasticache 13/10/2025 13/10/2025 https://www.youtube.com/watch?v=OOD2RwWuLRw\u0026list=PLahN4TLWtox2a3vElknwzU_urND8hLn1i\u0026index=217 3 - Thực hiện lab 05 - Thực hành: + Tạo EC2 và RDS + Triển khai ứng dụng trên EC2 và kết nối tới RDS + Biết cách sao lưu và khôi phục 14/10/2025 14/10/2025 https://000005.awsstudygroup.com/ 4 - Tìm hiểu về Hệ thống phân tán + Ôn tập mạng: TCP, HTTP; + Websocket 15/10/2025 15/10/2025 https://coderschool.notion.site/Naver-AI-Hackathon-Week-2-Web-Distributed-Systems-28bea86d567a80f0acf9e624986dcdf6 5 - Thực hành: + Tạo trò chơi cờ caro chẵn/lẻ nhiều người chơi 16/10/2025 16/10/2025 https://coderschool.notion.site/Week-2-Assignment-React-28bea86d567a8044bd23fd69e3d9b8df 6 - Thực hành: + Tiếp tục sửa lỗi và hoàn thiện trò chơi 17/10/2025 17/10/2025 https://github.com/Son2110/tic-tac-toe-even-odd Kết quả đạt được tuần 6: Hiểu các khái niệm cơ bản về cơ sở dữ liệu:\nRDBMS và NoSQL OLTP và OLAP Amazon RDS và Aurora Amazon Redshift Amazon ElastiCache Đã tạo và cấu hình thành công một Amazon RDS instance.\nBiết cách kết nối và tương tác với cơ sở dữ liệu từ xa bằng các SQL client hoặc công cụ dòng lệnh từ EC2 instance.\nTạo thành công trò chơi cờ caro chẵn/lẻ.\n"
},
{
	"uri": "http://localhost:1313/fcj-workshop/vi/1-worklog/1.7-week7/",
	"title": "Worklog Tuần 7",
	"tags": [],
	"description": "",
	"content": "Mục tiêu tuần 7: Hoàn thành các bài lab của module 7. Hoàn thành bài tập của Hackathon. Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Ôn tập kiến thức về các khái niệm cơ sở dữ liệu 20/10/2025 20/10/2025 3 - Tìm hiểu về Agile + Scrum + Kanban - Thực hành: Viết tầm nhìn sản phẩm (product vision) và bài thuyết trình (pitch) 21/10/2025 21/10/2025 https://coderschool.notion.site/Naver-AI-Hackathon-Week-3-From-Idea-to-Impact-292ea86d567a80779621c45b102205e7 4 - Thực hiện 2 bài lab 35 và 40 - Thực hành: + Sử dụng AWS Glue để quét dữ liệu trong S3 + Kết nối Amazon Athena với AWS Glue + Kết nối Amazon QuickSight với Amazon Athena 22/10/2025 22/10/2025 https://000035.awsstudygroup.com/ https://000040.awsstudygroup.com/ 5 - Thực hiện 2 bài lab 60 và 70 - Thực hành: + Sử dụng SDK để tạo bảng, CRUD dữ liệu trong Amazon DynamoDB + Xây dựng data lake với dữ liệu lưu trữ trong S3 23/10/2025 23/10/2025 https://000060.awsstudygroup.com/ https://000070.awsstudygroup.com/ 6 - Thực hiện 2 bài lab 72 và 73 - Thực hành: + Sử dụng AWS Glue để hồ sơ hóa, làm sạch và chuyển đổi dữ liệu thô một cách trực quan mà không cần viết code + Xây dựng dashboard thông qua QuickSight 24/10/2025 24/10/2025 https://000072.awsstudygroup.com/ https://000073.awsstudygroup.com/ Kết quả đạt được tuần 7: Đã tạo thành công tầm nhìn sản phẩm (product vision) và bài thuyết trình (pitch).\nHiểu kiến trúc của Serverless Data Lake và các dịch vụ Analytics:\nAWS Glue Amazon Athena Amazon QuickSight Thiết kế và xuất bản các dashboard tương tác bằng Amazon QuickSight để trực quan hóa dữ liệu chi tiết và hỗ trợ ra quyết định kinh doanh.\nSử dụng Amazon Athena để phân tích dữ liệu trực tiếp từ S3 bằng SQL tiêu chuẩn để phân tích chi phí và giám sát hiệu suất.\n"
},
{
	"uri": "http://localhost:1313/fcj-workshop/vi/1-worklog/1.8-week8/",
	"title": "Worklog Tuần 8",
	"tags": [],
	"description": "",
	"content": "Mục tiêu tuần 8: Ôn tập kiến thức từ module 1 đến 7. Tìm hiểu về Naver Clova Studio. Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Ôn tập kiến thức về AWS: + Tối ưu hóa chi phí (Cost Optimization) + EC2 cơ bản 27/10/2025 27/10/2025 3 - Tìm hiểu về Naver Clova Studio - Tìm kiếm ý tưởng cho Hackathon - Ôn tập về EC2 28/10/2025 28/10/2025 https://coderschool.notion.site/Naver-AI-Hackathon-Week-4-Web-Naver-AI-Clova-Studio-29bea86d567a80d6abdeeb0cef37d6c0 4 - Ôn tập S3 và Mô hình Trách nhiệm Chia sẻ (Shared Responsibility Model) 29/10/2025 29/10/2025 5 - Ôn tập các khái niệm về dữ liệu - Làm một số bài kiểm tra trên NotebookLM 30/10/2025 30/10/2025 6 - Làm bài kiểm tra trên NotebookLM - Ôn tập toàn bộ kiến thức từ module 1 đến 7 31/10/2025 31/10/2025 Kết quả đạt được tuần 8: Đã hiểu về Naver Clova Studio.\nĐã chốt thành công ý tưởng cho Hackathon là ứng dụng hỗ trợ người khiếm thính giao tiếp với người khác.\nĐã ôn tập toàn bộ kiến thức từ module 1 đến 7.\n"
},
{
	"uri": "http://localhost:1313/fcj-workshop/vi/1-worklog/1.9-week9/",
	"title": "Worklog Tuần 9",
	"tags": [],
	"description": "",
	"content": "Mục tiêu tuần 9: Xây dựng trang web demo. Kết nối S3 và CloudFront cho workshop. Tìm hiểu mô hình AI cho dự án Hackathon. Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Tạo ứng dụng cơ bản, triển khai Front-end (FE) lên S3 và CloudFront 03/11/2025 03/11/2025 3 - Tạo API Gateway và Lambda function cho chức năng đăng nhập/đăng xuất - Sửa các lỗi liên quan đến CORS 04/11/2025 04/11/2025 4 - Tìm hiểu về mô hình AI - Học cách chạy mô hình này 05/11/2025 05/11/2025 https://github.com/Etdihatthoc/Multi-VSL_WACV_2025/ 5 - Tạo một trang web đơn giản tích hợp camera cho dự án - Tìm hiểu về mô hình VSL (Vietnamese Sign Language) mới 06/11/2025 06/11/2025 https://github.com/photienanh/Vietnamese-Sign-Language-Recognition 6 - Triển khai tích hợp mô hình AI VSL vào dự án 07/11/2025 07/11/2025 Kết quả đạt được tuần 9: Đã xây dựng thành công trang web đơn giản cho workshop và hackathon.\nĐã kết nối thành công S3 và CloudFront để triển khai Front-end.\nĐã tích hợp thành công mô hình AI VSL vào trang web.\n"
},
{
	"uri": "http://localhost:1313/fcj-workshop/vi/5-workshop/5.1-workshop-overview/",
	"title": "Giới thiệu",
	"tags": [],
	"description": "",
	"content": "Kiến trúc Phi Máy Chủ \u0026amp; Hướng Sự kiện (Serverless \u0026amp; Event-Driven Architecture) Kiến trúc Phi Máy Chủ (Serverless Architecture): Workshop này áp dụng mô hình gốc đám mây (cloud-native) với các dịch vụ như AWS Lambda, Amazon API Gateway, và Amazon DynamoDB. Cách tiếp cận này cho phép mã chạy để phản hồi các yêu cầu mà không cần cấp phát hay quản lý máy chủ, vì AWS sẽ xử lý tất cả việc tự động điều chỉnh quy mô và quản lý cơ sở hạ tầng. Kiến trúc Hướng Sự kiện (Event-Driven Architecture): Cốt lõi của hệ thống hoạt động trên cơ sở hướng sự kiện. Thay vì các dịch vụ liên tục thăm dò dữ liệu, các sự kiện cụ thể—như dữ liệu đọc từ cảm biến IoT hoặc các cuộc gọi API từ người dùng—sẽ kích hoạt các quy trình làm việc tiếp theo. Điều này được điều phối bởi AWS IoT Core và Amazon EventBridge, tạo ra một hệ thống có tính linh hoạt và khả năng mở rộng cao. Tổng quan về Workshop (Workshop Overview) Trong workshop này, bạn sẽ triển khai một nền tảng dữ liệu phi máy chủ toàn diện trên AWS để quản lý giám sát môi trường theo thời gian thực cho thiết lập văn phòng thông minh 8 phòng. Hệ thống tích hợp AWS IoT Core, Lambda, DynamoDB, S3, CloudFront, và Amazon Cognito. Dữ liệu cảm biến được chuyển tiếp từ thiết bị biên (hoặc tập lệnh mô phỏng), được đưa vào AWS, lưu trữ trong các bảng DynamoDB và được xử lý bởi các hàm Lambda để cập nhật bảng điều khiển quản lý. Các sự kiện quan trọng được định tuyến qua EventBridge để kích hoạt cảnh báo, thể hiện một kiến trúc có tính sẵn sàng cao, chi phí thấp và khả năng mở rộng liền mạch.\n"
},
{
	"uri": "http://localhost:1313/fcj-workshop/vi/4-eventparticipated/4.2-event2/",
	"title": "Event 2",
	"tags": [],
	"description": "",
	"content": "Báo cáo tổng hợp: \u0026ldquo;AWS Cloud Mastery Series #1: AI/ML/GenAI trên AWS\u0026rdquo; Mục tiêu tham dự Tìm hiểu khái niệm cơ bản về Mô hình nền tảng (Foundation Model). Học hỏi các phương pháp kỹ thuật đặt câu lệnh (Prompting) để tối ưu kết quả đầu ra. Khám phá khả năng của Generative AI thông qua dịch vụ Amazon Bedrock. Tìm hiểu về kiến trúc RAG (Retrieval-Augmented Generation) và cách tích hợp cơ sở tri thức (Knowledge Base). Diễn giả Danh Hoang Hieu Nghi Lam Truong Kiet Dinh Le Hoang Anh Những điểm nổi bật Kỹ thuật Prompting (Kỹ thuật gợi ý) Tối ưu hóa câu lệnh: Hiểu được tầm quan trọng của việc soạn thảo prompt rõ ràng và cụ thể để mô hình AI trả về kết quả chính xác hơn. Tư duy chuỗi (Chain of Thought): Một phương pháp hướng dẫn AI xử lý vấn đề từng bước một, giúp cải thiện khả năng suy luận logic. RAG (Retrieval-Augmented Generation) Mở rộng khả năng của AI: Hiểu được cách kết hợp AI với nguồn dữ liệu nội bộ của doanh nghiệp thay vì chỉ dựa vào dữ liệu huấn luyện có sẵn. Tính chính xác và thời gian thực: RAG giúp giảm thiểu hiện tượng \u0026ldquo;ảo giác\u0026rdquo; (AI tự bịa thông tin) và đảm bảo câu trả lời luôn được cập nhật mới nhất. Vector Embedding (Nhúng Vector) Biểu diễn dữ liệu: Cách chuyển đổi văn bản thành các vector số học để máy tính có thể hiểu được ngữ nghĩa và mối quan hệ giữa các từ. Nắm bắt ngữ cảnh: Các mô hình embedding giúp hệ thống hiểu được sắc thái của văn bản. Đa ngôn ngữ: Khả năng so sánh và tìm kiếm ngữ nghĩa tương đồng giữa các ngôn ngữ khác nhau. Các dịch vụ AI của AWS Amazon Rekognition: Nhận diện hình ảnh và video. Amazon Translate: Dịch thuật tự động. Amazon Textract: Trích xuất dữ liệu từ văn bản quét. Amazon Transcribe: Chuyển đổi giọng nói thành văn bản. Amazon Polly: Chuyển đổi văn bản thành giọng nói tự nhiên. Amazon Comprehend: Phân tích văn bản và cảm xúc. Amazon Kendra: Công cụ tìm kiếm thông minh cho doanh nghiệp. Amazon Lookout: Phát hiện bất thường trong dữ liệu. Amazon Personalize: Hệ thống gợi ý cá nhân hóa. Bài học rút ra Cải thiện kỹ năng Prompting Cung cấp ngữ cảnh: Việc đưa ra các ví dụ cụ thể (few-shot prompting) giúp AI hiểu rõ yêu cầu hơn. Hướng dẫn chi tiết: Giải thích cho AI quy trình xử lý từng bước để giải quyết vấn đề. Ứng dụng của RAG Giảm thiểu sai sót: Kết nối với nguồn kiến thức đã được kiểm chứng của doanh nghiệp. Nâng cao Chatbot: Tích hợp dữ liệu thời gian thực để Chatbot phản hồi thông minh hơn. Tìm kiếm cá nhân hóa: Dựa trên lịch sử và chân dung người dùng. Tổng hợp dữ liệu: Trích xuất thông tin từ các tài liệu giao dịch. Amazon Titan Embeddings Tìm kiếm theo ngữ nghĩa: Cho phép tìm kiếm dựa trên ý nghĩa của từ khóa thay vì chỉ khớp ký tự. Hiệu năng: Hỗ trợ xử lý lượng token lớn và đa dạng ngôn ngữ. Kế hoạch áp dụng vào công việc Nghiên cứu thêm: Tiếp tục tìm hiểu sâu hơn về các dịch vụ AI để đánh giá khả năng áp dụng cho các dự án tương lai. Thử nghiệm: Bắt đầu thực hành các kỹ thuật prompting đã học để nâng cao hiệu quả làm việc. Trải nghiệm sự kiện Tham dự workshop “AI/ML/GenAI trên AWS” là một cơ hội quý báu giúp tôi bước đầu tiếp cận với lĩnh vực AI trên nền tảng đám mây. Dưới đây là những trải nghiệm chính:\nHọc hỏi từ chuyên gia Các diễn giả từ FACJ đã chia sẻ những kinh nghiệm thực tiễn (best practices) về việc triển khai AI, giúp tôi hình dung rõ hơn về quy trình áp dụng vào thực tế. Thông qua các ví dụ cụ thể, tôi đã hiểu rõ hơn về cách vận hành của kỹ thuật prompting. Khám phá thực tế các dịch vụ Việc xem demo trực tiếp giúp tôi hiểu cơ chế hoạt động của các dịch vụ AWS AI và cách chúng giải quyết các bài toán đời sống. Hướng dẫn xây dựng Agent Thu nhận được kiến thức nền tảng cần thiết để bắt đầu tìm hiểu về việc xây dựng các Tác nhân AI (AI Agent). Một số hình ảnh tại sự kiện Nhìn chung, sự kiện đã trang bị cho tôi những kiến thức nền tảng quan trọng về Generative AI, tạo tiền đề để tôi có thể nghiên cứu và ứng dụng vào các dự án trong tương lai.\n"
},
{
	"uri": "http://localhost:1313/fcj-workshop/vi/1-worklog/1.10-week10/",
	"title": "Worklog Tuần 10",
	"tags": [],
	"description": "",
	"content": "Mục tiêu tuần 10: Chuyển đổi dự án sang nền tảng GitLab. Cấu hình CI/CD cho dự án. Tìm hiểu cách dịch liên tục các từ ngữ bằng mô hình AI. Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Tìm giải pháp để mô hình có thể dịch video dài chứa nhiều cử chỉ 10/11/2025 10/11/2025 3 - Chuyển dự án từ GitHub sang GitLab - Tìm hiểu cách sử dụng GitLab - Cấu hình CI/CD 11/11/2025 11/11/2025 https://gitlab.com/son2110-group/AWS-Project 4 - Triển khai logic cửa sổ trượt (sliding window) ở Back-end (BE) để dịch từ liên tục 13/11/2025 13/11/2025 https://chatgpt.com/s/t_6911e6be651081918559f768ba18a0be 5 - Sửa lỗi và kiểm thử web 14/11/2025 14/11/2025 6 - Triển khai phân đoạn dựa trên khoảng nghỉ (pause-based segmentation) ở Back-end 15/11/2025 15/11/2025 Kết quả đạt được tuần 10: Đã cấu hình thành công CI/CD trên GitLab để triển khai lên S3 và CloudFront.\nTriển khai thành công 2 phương pháp dịch từ liên tục lên web.\nĐã kiểm thử độ chính xác của cả 2 phương pháp.\n"
},
{
	"uri": "http://localhost:1313/fcj-workshop/vi/1-worklog/1.11-week11/",
	"title": "Worklog Tuần 11",
	"tags": [],
	"description": "",
	"content": "Mục tiêu tuần 11: Xây dựng sản phẩm MVP cho dự án Hackathon. Tạo API Gateway và Lambda function cho workshop. Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Tham gia AWS Cloud Mastery Series #2 17/11/2025 17/11/2025 3 - Tạo chức năng quên mật khẩu cho web - Sửa lỗi Lambda và CORS 18/11/2025 18/11/2025 4 - Triển khai cắt video 3 giây trên Front-end (FE) và kiểm thử 19/11/2025 19/11/2025 5 - Triển khai Web Speech API vào dự án và tiếp tục kiểm thử - Học trên Coursera 20/11/2025 20/11/2025 https://www.coursera.org/learn/research-methods 6 - Cải thiện giao diện (UI) web cho chức năng quay video và cắt 3 giây - Học trên Coursera 21/11/2025 21/11/2025 https://www.coursera.org/learn/research-methodologies Kết quả đạt được tuần 11: Đã tạo thành công chức năng quên mật khẩu cho workshop.\nĐã xây dựng thành công dự án TalkSign cho Hackathon.\n"
},
{
	"uri": "http://localhost:1313/fcj-workshop/vi/1-worklog/1.12-week12/",
	"title": "Worklog Tuần 12",
	"tags": [],
	"description": "",
	"content": "Mục tiêu tuần 12: Hoàn thành việc thuyết trình tại ngày demo Hackathon. Tiếp tục hoàn thiện workshop. Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Học trên Coursera - Chuẩn bị cho bài thuyết trình Hackathon 24/11/2025 24/11/2025 https://www.coursera.org/learn/introduction-to-research-for-essay-writing?specialization=academic-english 3 - Thuyết trình online tại ngày demo Hackathon - Tạo function và kết nối API tới web + RoomList + RoomConfig 25/11/2025 25/11/2025 https://drive.google.com/file/d/1qZgxEglgt08jQaZD7WQv0CcijgbpNH53/view?usp=drive_link 4 - Tạo Landing page - Thay đổi giao diện (UI) cho dự án - Tạo function UserList 26/11/2025 26/11/2025 5 - Tìm hiểu về cách deploy GitHub Pages - Thiết kế lại luồng hoạt động (flow) của dự án 27/11/2025 27/11/2025 6 - Triển khai Admin Dashboard mới và chức năng đăng ký (sign up) 28/11/2025 28/11/2025 Kết quả đạt được tuần 12: Đã thuyết trình thành công tại ngày demo Hackathon.\nĐã thiết kế lại thành công luồng hoạt động (flow) của dự án.\nĐã triển khai thành công Admin Dashboard mới và chức năng đăng ký.\n"
},
{
	"uri": "http://localhost:1313/fcj-workshop/vi/1-worklog/1.13-week13/",
	"title": "Worklog Tuần 13",
	"tags": [],
	"description": "",
	"content": "Mục tiêu tuần 13: Hoàn thành toàn bộ workshop. Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Làm lại Lambda đăng nhập và thiết kế giao diện đăng nhập cho hai loại tài khoản (Admin, Manager) - Tạo chức năng CRUD cho tài khoản Admin 01/12/2025 01/12/2025 3 - Sửa lỗi đăng nhập cho tài khoản Manager - Sửa 2 hàm ListRoom và UpdateRoom - Tạo biểu đồ hiển thị dữ liệu - Tạo chức năng thêm phòng mới tích hợp với IoT Core 02/12/2025 02/12/2025 4 - Triển khai thiết bị IoT ảo trên máy tính cá nhân để nhận và gửi dữ liệu tới AWS 03/12/2025 03/12/2025 5 - Sửa một số lỗi giao diện (UI) và script Python giả lập thiết bị IoT 04/12/2025 04/12/2025 6 - Kiểm thử và tối ưu hóa website 05/12/2025 05/12/2025 Kết quả đạt được tuần 13: Đã triển khai thành công script Python giả lập thiết bị IoT cục bộ, thiết lập giao tiếp MQTT hai chiều (Gửi Telemetry \u0026amp; Nhận Config) với AWS IoT Core.\nHoàn thành toàn bộ nội dung workshop.\n"
},
{
	"uri": "http://localhost:1313/fcj-workshop/vi/2-proposal/",
	"title": "Bản đề xuất",
	"tags": [],
	"description": "",
	"content": "Hệ thống Quản lý Văn phòng Thông minh cho Phòng Nghiên cứu Giải pháp AWS Serverless hợp nhất cho giám sát và điều khiển văn phòng thông minh theo thời gian thực 1. Tóm tắt điều hành Hệ thống Quản lý Văn phòng Thông minh (Smart Office Management System) được đề xuất bởi Nhóm Skyscraper từ FPTU HCM Campus, lấy cảm hứng từ sự vận hành xuất sắc quan sát được trong chuyến đi thực tế đến văn phòng AWS tại TP. Hồ Chí Minh. Việc quản lý văn phòng truyền thống hiện nay thiếu khả năng hiển thị thời gian thực về điều kiện phòng (nhiệt độ, độ ẩm, ánh sáng) và phụ thuộc nhiều vào sự giám sát thủ công. Để giải quyết vấn đề này, chúng tôi đề xuất xây dựng một Bảng điều khiển Quản lý (Management Console) tập trung, được xây dựng trên kiến trúc AWS Serverless hoàn chỉnh. Bằng cách tận dụng các dịch vụ như AWS IoT Core, Lambda và DynamoDB, hệ thống thu thập dữ liệu cảm biến mỗi 2-5 phút để hỗ trợ giám sát thời gian thực và cho phép quản trị viên quản lý cấu hình thiết bị từ xa. Dự án này cũng đóng vai trò là chiến lược \u0026ldquo;First Cloud AI Journey\u0026rdquo;, giúp nhóm thu hẹp khoảng cách giữa kiến thức lý thuyết và ứng dụng thực tế của Điện toán Đám mây.\n2. Tuyên bố vấn đề Vấn đề hiện tại Hiện nay, việc quản lý môi trường văn phòng trong các phòng lab nghiên cứu đòi hỏi sự can thiệp thủ công để kiểm tra trạng thái thiết bị (đèn, điều hòa) và điều kiện môi trường. Các quản lý thường thiếu dữ liệu cần thiết để đưa ra quyết định sáng suốt về việc sử dụng năng lượng hoặc sự thoải mái của phòng. Việc vận hành thiết bị theo lịch trình cố định (ví dụ: 8 giờ sáng đến 5 giờ chiều) mà không quan tâm đến mức độ sử dụng thực tế hoặc các yếu tố môi trường dẫn đến lãng phí năng lượng. Hơn nữa, nếu không có bảng điều khiển tập trung, quản trị viên không thể nhanh chóng phát hiện các bất thường hoặc cấu hình cài đặt cho nhiều phòng một cách hiệu quả.\nGiải pháp Nền tảng sử dụng AWS IoT Core để tiếp nhận dữ liệu MQTT từ cảm biến phòng, AWS Lambda và API Gateway cho logic xử lý backend, Amazon DynamoDB để lưu trữ nhật ký cảm biến và cấu hình phòng, cùng với Amazon S3 kết hợp CloudFront để lưu trữ bảng điều khiển quản lý web. Quyền truy cập được bảo mật nghiêm ngặt thông qua Amazon Cognito. Amazon EventBridge được sử dụng để xử lý các tác vụ tự động hóa theo lịch trình, trong khi Amazon SNS đảm bảo thông báo kịp thời cho các cảnh báo hệ thống. Giải pháp này thay thế việc theo dõi thủ công bằng một bảng điều khiển quản lý kỹ thuật số, thời gian thực, có khả năng giám sát nhiều phòng cùng lúc.\nLợi ích và hoàn vốn đầu tư (ROI) Hệ thống Quản lý Văn phòng Thông minh nâng cao hiệu quả vận hành bằng cách cung cấp một giao diện giám sát và cấu hình duy nhất. Nó trao quyền cho quản lý phòng lab điều khiển thiết bị từ xa và đưa ra quyết định dựa trên dữ liệu. Ngoài những cải tiến về vận hành, dự án cung cấp một nền tảng serverless có thể tái sử dụng cho các nghiên cứu IoT trong tương lai tại trường đại học.\nChi phí vận hành hàng tháng ước tính khoảng $1.81 USD, tận dụng AWS Free Tier cho các dịch vụ như Lambda, API Gateway và DynamoDB. Chi phí chính bao gồm CloudFront ($1.27) và CloudWatch ($0.25), tổng cộng khoảng $21.72 USD mỗi năm. Vì hệ thống tận dụng phần cứng ESP32 và cảm biến hiện có, không có thêm chi phí vốn đầu tư. Hệ thống mang lại giá trị ngay lập tức thông qua việc tiết kiệm thời gian và giảm nỗ lực quản lý.\n3. Kiến trúc giải pháp Hệ thống Smart Office áp dụng kiến trúc AWS hoàn toàn serverless được tối ưu hóa cho hiệu quả chi phí và khả năng mở rộng. Dữ liệu từ nhiều hub cảm biến được truyền đến AWS IoT Core, được xử lý bởi các hàm Lambda và lưu trữ trong DynamoDB để giám sát thời gian thực và quản lý cấu hình. EventBridge tự động hóa các hành động thiết bị theo lịch trình, trong khi SNS xử lý thông báo hệ thống. Bảng điều khiển web được lưu trữ trên S3 và phân phối an toàn qua CloudFront, với xác thực người dùng được quản lý thông qua Amazon Cognito. Kiến trúc này giảm thiểu chi phí vận hành và đảm bảo độ tin cậy cao cho việc kiểm soát môi trường thông minh.\nDịch vụ AWS sử dụng AWS IoT Core: Tiếp nhận và quản lý dữ liệu MQTT từ các hub phòng thông minh, cho phép giao tiếp an toàn giữa thiết bị biên và đám mây. AWS Lambda: Thực thi logic backend để xử lý dữ liệu cảm biến, xử lý các yêu cầu API và thực hiện các lệnh quản lý (Tính toán Serverless). Amazon API Gateway: Cung cấp các điểm cuối RESTful an toàn cho bảng điều khiển web tương tác với các dịch vụ backend. Amazon DynamoDB: Cung cấp lưu trữ NoSQL nhanh chóng cho cấu hình phòng, trạng thái thiết bị và nhật ký cảm biến lịch sử. Amazon EventBridge: Điều phối các quy trình làm việc theo sự kiện, chẳng hạn như cập nhật cấu hình theo lịch trình hoặc kiểm tra nhịp tim (heartbeat). Amazon SNS: Gửi thông báo email cho quản trị viên liên quan đến cảnh báo hệ thống hoặc cập nhật quan trọng. Amazon S3: Lưu trữ các tài sản tĩnh frontend (HTML, CSS, JS) cho Bảng điều khiển Quản lý. Amazon CloudFront: Phân phối ứng dụng web toàn cầu với độ trễ thấp và bảo mật SSL. Amazon Cognito: Quản lý danh tính người dùng, xác thực và kiểm soát truy cập cho Bảng điều khiển Quản lý. Amazon CloudWatch: Thu thập nhật ký và số liệu để giám sát sức khỏe hệ thống và gỡ lỗi thực thi Lambda. Thiết kế thành phần Sensor Hubs: Each IoT-enabled room device collects environmental data (temperature, humidity, light, etc.) and sends it to AWS IoT Core every two minutes. Sensor Hubs: Các thiết bị hỗ trợ IoT (ESP32) trong mỗi phòng thu thập dữ liệu từ xa (nhiệt độ, độ ẩm, ánh sáng) và truyền đến AWS IoT Core vài phút một lần. Data Ingestion (Tiếp nhận dữ liệu): Các quy tắc AWS IoT Core kích hoạt HandleTelemetry Lambda, chức năng này xác thực dữ liệu và lưu vào Amazon DynamoDB. Configuration Management (Quản lý cấu hình): Quản trị viên sử dụng bảng điều khiển để cập nhật cài đặt phòng. RoomConfigHandler Lambda cập nhật DynamoDB và đẩy các thay đổi xuống thiết bị qua IoT Core Shadows hoặc MQTT. User Interaction (Tương tác người dùng): Bảng điều khiển Web (trên S3/CloudFront) trực quan hóa dữ liệu thời gian thực và cung cấp giao diện điều khiển. User Authentication (Xác thực người dùng): Amazon Cognito đảm bảo chỉ các thành viên phòng lab được ủy quyền mới có thể đăng nhập và truy cập dữ liệu phòng nhạy cảm. Monitoring \u0026amp; Reliability (Giám sát \u0026amp; Độ tin cậy): Amazon CloudWatch theo dõi hiệu suất hệ thống, đảm bảo tính sẵn sàng cao và khắc phục sự cố nhanh chóng. 4. Triển khai kỹ thuật Giai đoạn triển khai Nghiên cứu \u0026amp; Nền tảng (Tuần 1-7): Nghiên cứu các dịch vụ AWS cốt lõi (IoT Core, Lambda, DynamoDB, S3, API Gateway, Cognito) và hiểu các mô hình thiết kế Serverless. Thiết kế Kiến trúc \u0026amp; Dự toán (Tuần 8): Hoàn thiện sơ đồ giải pháp cho thiết lập 8 phòng và sử dụng AWS Pricing Calculator để dự báo ngân sách. Phát triển (Tuần 9-11): Triển khai firmware/kịch bản mô phỏng dữ liệu IoT. Phát triển Backend: Các hàm Lambda, bảng DynamoDB và tài nguyên API Gateway sử dụng CloudFormation/CDK. Phát triển Frontend: Xây dựng Bảng điều khiển Quản lý và tích hợp với các API. Kiểm thử \u0026amp; Triển khai (Tuần 12): Thực hiện kiểm thử toàn diện (end-to-end), xác thực luồng dữ liệu từ cảm biến đến bảng điều khiển và triển khai hệ thống lên môi trường production. Yêu cầu kỹ thuật Tầng Phần cứng: Các Sensor Hub dựa trên ESP32 giám sát các chỉ số môi trường. Tầng Đám mây: Một stack hoàn toàn serverless trên AWS (IoT Core, Lambda, DynamoDB, API Gateway, S3, CloudFront, Cognito, EventBridge, SNS). DevOps: Cơ sở hạ tầng dưới dạng Mã (IaC) sử dụng AWS CloudFormation để triển khai có thể tái lập. Giao diện: Bảng điều khiển web tương thích (responsive) cho phép giám sát thời gian thực và cập nhật cấu hình. 5. Lộ trình \u0026amp; Mốc triển khai Lộ trình Tuần 1–7: Tìm hiểu sâu về các dịch vụ AWS và hoàn thành khóa đào tạo cơ bản \u0026ldquo;First Cloud AI Journey\u0026rdquo;. Tuần 8: Thiết kế kiến trúc hệ thống và hoàn thiện dự toán chi phí. Tuần 9–11: Giai đoạn phát triển cốt lõi (Logic Backend, Lược đồ Database, Tích hợp giao diện Frontend). Tuần 12: Kiểm thử tích hợp hệ thống, gỡ lỗi và trình bày Go-Live cuối cùng. 6. Ước tính ngân sách Có thể xem chi phí trên AWS Pricing Calculator\nHoặc tải tệp ước tính ngân sách.\nChi phí hạ tầng Dịch vụ AWS:\nAmazon DynamoDB: Miễn phí (Gói Always Free: 25GB Lưu trữ). AWS Lambda: Miễn phí (Gói Always Free: 1 triệu yêu cầu/tháng). AWS IoT Core: $0.18/tháng (8 thiết bị, gửi dữ liệu mỗi 2 phút). Amazon API Gateway: Miễn phí (Gói Free Tier: 1 triệu cuộc gọi/tháng trong 12 tháng). Amazon S3: Miễn phí (Lưu trữ Standard \u0026lt; 5GB). Amazon CloudFront: $1.27/tháng (Dựa trên ước tính truyền dữ liệu và yêu cầu). Amazon EventBridge: Miễn phí (Sự kiện trong gói Free Tier). Amazon SNS: $0.02/tháng (Thông báo qua Email). Amazon CloudWatch: $0.25/tháng (Thu thập và lưu trữ log). Amazon Cognito: Miễn phí (Gói Free Tier: 50,000 MAUs). Phần cứng: Giả lập script Tổng cộng: ≈ $1.81/tháng, hoặc $21.72/năm (được tối ưu hóa trong giới hạn AWS Free Tier).\n7. Đánh giá rủi ro Ma trận rủi ro Vấn đề Kết nối IoT: Tác động trung bình, xác suất trung bình. Dữ liệu Cảm biến Không chính xác: Tác động trung bình, xác suất thấp. Phí AWS Ngoài dự kiến: Tác động thấp, xác suất thấp (do cảnh báo ngân sách chặt chẽ). Cấu hình Bảo mật Sai: Tác động cao, xác suất thấp. Chiến lược giảm thiểu Kết nối: Triển khai logic thử lại (retry) trên thiết bị biên và lưu đệm cục bộ. Chi phí: Cấu hình AWS Budgets để cảnh báo khi chi tiêu vượt quá $5.00. Bảo mật: Thực thi các chính sách IAM nghiêm ngặt (Đặc quyền Tối thiểu) và yêu cầu xác thực cho tất cả truy cập API qua Cognito. Độ tin cậy: Sử dụng CloudWatch Logs để truy vết lỗi trong thực thi Lambda ngay lập tức. Kế hoạch dự phòng Kích hoạt các điều khiển ghi đè thủ công nếu hệ thống đám mây không khả dụng. Duy trì bản sao lưu của các mẫu CloudFormation để triển khai lại nhanh chóng. 8. Kết quả kỳ vọng Cải tiến kỹ thuật: Thay thế việc kiểm tra thủ công bằng giám sát kỹ thuật số thời gian thực. Cung cấp một nền tảng tập trung để quản lý cấu hình trên nhiều phòng. Thiết lập một kiến trúc có khả năng mở rộng để hỗ trợ nhiều thiết bị hơn trong tương lai. Giá trị dài hạn: Phục vụ như một trung tâm học tập thực tế cho sinh viên để làm chủ các công nghệ AWS Serverless. Cung cấp thông tin chi tiết về dữ liệu có thể dẫn đến các chính sách sử dụng năng lượng tốt hơn trong phòng lab. Chứng minh một giải pháp đám mây hiệu quả về chi phí, sẵn sàng cho sản xuất. Proposal Link Smart_Office_Proposal\n"
},
{
	"uri": "http://localhost:1313/fcj-workshop/vi/5-workshop/5.2-prerequiste/",
	"title": "Các bước chuẩn bị",
	"tags": [],
	"description": "",
	"content": "Tạo IAM User cho workshop này Trong AWS Management Console, tìm kiếm và chọn IAM Điều hướng đến User, nhấp vào Create user Tại mục User name, nhập admin-user Tích chọn Provide user access to the AWS Management Console - optional Tại mục Console password, chọn Custom password Nhập mật khẩu cho user của bạn Bỏ chọn Users must create a new password at next sign-in - Recommended để thao tác dễ dàng hơn Nhấp Next Tại mục Permissions options, chọn Attach policies directly Nhấp Create policy Bạn sẽ được điều hướng đến trang Create policy Tại mục Policy editor, chuyển sang JSON Sao chép và dán đoạn policy này vào { \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Sid\u0026#34;: \u0026#34;InfrastructureManagement\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;cloudformation:*\u0026#34;, \u0026#34;iam:*\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;*\u0026#34; }, { \u0026#34;Sid\u0026#34;: \u0026#34;BackendComputeAndAPI\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;lambda:*\u0026#34;, \u0026#34;apigateway:*\u0026#34;, \u0026#34;execute-api:*\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;*\u0026#34; }, { \u0026#34;Sid\u0026#34;: \u0026#34;DatabaseAndAuth\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;dynamodb:*\u0026#34;, \u0026#34;cognito-idp:*\u0026#34;, \u0026#34;cognito-identity:*\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;*\u0026#34; }, { \u0026#34;Sid\u0026#34;: \u0026#34;IoTServices\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;iot:*\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;*\u0026#34; }, { \u0026#34;Sid\u0026#34;: \u0026#34;StorageAndHosting\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;s3:*\u0026#34;, \u0026#34;cloudfront:*\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;*\u0026#34; }, { \u0026#34;Sid\u0026#34;: \u0026#34;MonitoringAndLogging\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;logs:*\u0026#34;, \u0026#34;cloudwatch:*\u0026#34;, \u0026#34;events:*\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;*\u0026#34; } ] } Nhấp Next Tại mục Policy name, nhập tên policy của bạn (Ví dụ: SmartOfficeAdminFullAcccess) Thêm Tags để quản lý chi phí và vận hành (Key: Project, Value: SmartOffice; Key: Environment, Value: Dev) Nhấp Create policy Quay lại Step 2 Set permissions của phần Create user Tìm kiếm và chọn tên policy của bạn Nhấp Next Thêm Tags để quản lý chi phí và vận hành (Key: Project, Value: SmartOffice; Key: Environment, Value: Dev) Nhấp Create user Đăng nhập bằng tài khoản User của bạn để bắt đầu workshop này "
},
{
	"uri": "http://localhost:1313/fcj-workshop/vi/3-blogstranslated/",
	"title": "Các bài blogs đã dịch",
	"tags": [],
	"description": "",
	"content": "Mục này sẽ liệt kê và giới thiệu tóm tắt về các bài blog kỹ thuật mà bạn đã dịch:\nBlog 1 - Rox tăng tốc năng suất bán hàng với AI agents được hỗ trợ bởi Amazon Bedrock Bài viết này giới thiệu cách Rox sử dụng Amazon Bedrock để xây dựng một \u0026ldquo;Hệ điều hành doanh thu\u0026rdquo; (Revenue Operating System). Bạn sẽ tìm hiểu cách các Tác nhân AI (AI Agents) giúp tự động hóa các quy trình bán hàng phức tạp—từ nghiên cứu khách hàng và tìm kiếm liên hệ đến soạn thảo đề xuất—cho phép đội ngũ bán hàng tăng năng suất và tập trung vào các cơ hội có giá trị cao.\nBlog 2 - Cách Laravel Nightwatch xử lý hàng tỷ sự kiện observability theo thời gian thực với Amazon MSK và ClickHouse Cloud Bài blog này đi sâu vào kiến trúc kỹ thuật của Laravel Nightwatch, một nền tảng giám sát hiệu suất ứng dụng. Nội dung mô tả cách họ kết hợp Amazon MSK và ClickHouse Cloud để xây dựng một đường ống xử lý luồng (streaming pipeline) có khả năng mở rộng, xử lý hàng tỷ sự kiện mỗi ngày với độ trễ dưới một giây trong khi vẫn đảm bảo hiệu quả chi phí.\nBlog 3 - Cách xuất dữ liệu ra Amazon S3 Tables bằng AWS Step Function Distributed Map Đây là một hướng dẫn kỹ thuật chi tiết về việc xây dựng quy trình làm việc ETL không máy chủ (serverless). Bài viết minh họa cách sử dụng AWS Step Functions Distributed Map để xử lý khối lượng lớn dữ liệu song song (ví dụ: trích xuất thông tin từ tệp PDF bằng Textract) và xuất dữ liệu có cấu trúc trực tiếp vào Amazon S3 Tables ở định dạng Apache Iceberg để phân tích.\n"
},
{
	"uri": "http://localhost:1313/fcj-workshop/vi/4-eventparticipated/4.3-event3/",
	"title": "Event 3",
	"tags": [],
	"description": "",
	"content": "Báo cáo tổng hợp: \u0026ldquo;AWS Cloud Mastery Series #2: DevOps on AWS\u0026rdquo; Mục tiêu buổi học Hiểu thế nào là tư duy DevOps. Biết về các dịch vụ AWS cho DevOps và quy trình CI/CD. Tìm hiểu khái niệm \u0026ldquo;Cơ sở hạ tầng bằng mã\u0026rdquo; (IaC). Khám phá các dịch vụ Container trên AWS. Cách giám sát và quan sát hệ thống (Monitoring \u0026amp; Observability). Nghe các kinh nghiệm thực tế (Best Practices) và bài học xương máu. Diễn giả Truong Quang Tinh Nghiem Le Long Huynh Quy Pham Những điểm hay ho mình ghi lại được Tư duy DevOps (DevOps Mindset) Hợp tác là chính: Dev và Ops phải làm việc chung, chia sẻ trách nhiệm chứ không đổ lỗi. Tự động hóa tất cả: Cái gì lặp lại thì nên viết tool tự động, đừng làm tay. Học liên tục: Công nghệ đổi mới liên tục nên phải chịu khó học và thử nghiệm cái mới. Đo lường: Làm gì cũng phải có số liệu để biết tốt hay xấu. Hành trình làm DevOps (Người mới nên biết) Nên làm (Do):\nBắt đầu từ những cái cơ bản nhất (Linux, Network\u0026hellip;). Học đi đôi với hành: Tự tay làm các dự án thực tế. Ghi chép tài liệu (Document) lại mọi thứ mình làm. Học cái nào chắc cái đó, đừng lan man. Rèn luyện kỹ năng mềm (giao tiếp). Đừng làm (Don\u0026rsquo;t):\nĐừng kẹt trong \u0026ldquo;địa ngục hướng dẫn\u0026rdquo; (xem tutorial suốt mà không tự làm). Đừng copy-paste code một cách mù quáng mà không hiểu nó chạy sao. Đừng so sánh mình với người khác, mỗi người một lộ trình. Đừng bỏ cuộc khi gặp lỗi (bug). Quy trình CI/CD Hiểu vòng đời của ứng dụng: Từ lúc viết code (coding), kiểm thử (testing), xem lại (review), chạy thử (pre-prod) đến lúc đưa ra cho người dùng thật (production). Cơ sở hạ tầng bằng mã (IaC) Nguyên lý: Dùng dòng lệnh (code) để quản lý tài nguyên cloud chứ không ngồi click chuột thủ công. Tự động hóa: Tự động tạo, sửa, xóa hạ tầng để tránh sai sót. Công cụ: Terraform, OpenTofu, Pulumi. Dịch vụ Container trên AWS Quản lý container bằng Docker, Kubernetes, Amazon ECR và Amazon EKS. Amazon App Runner: Một dịch vụ khá hay giúp triển khai web app trực tiếp từ code mà không cần lo về server hay cấu hình phức tạp (rất hợp cho người mới). Giám sát \u0026amp; Quan sát (Monitoring \u0026amp; Observability) Áp dụng các phương pháp chuẩn với Amazon CloudWatch và Amazon X-Ray để biết hệ thống có đang \u0026ldquo;khỏe\u0026rdquo; không. Bài học rút ra Các chỉ số DevOps cần quan tâm Theo dõi xem việc triển khai có ổn định không. Giúp hệ thống linh hoạt hơn, ít lỗi hơn. Đảm bảo trải nghiệm người dùng tốt nhất. Chứng minh được công nghệ mình dùng là đáng tiền. Sự liên tục trong CI/CD Hiểu được bức tranh toàn cảnh của một đường ống (pipeline) CI/CD nó chạy từ đầu đến cuối như thế nào. IaC trong AWS Biết cách dùng Amazon CloudFormation để tạo các mẫu (template) dựng sẵn hạ tầng, đỡ phải làm tay nhiều lần. Áp dụng vào thực tế Xây lộ trình: Tự lên kế hoạch học tập để theo nghề DevOps. Thử nghiệm CI/CD: Thử áp dụng pipeline tự động vào dự án hiện tại (đỡ phải deploy tay). Làm Template: Viết sẵn các mẫu code hạ tầng để dùng lại, giảm thiểu lỗi do con người (human errors). Trải nghiệm tham gia Tham gia buổi workshop “DevOps on AWS” thực sự rất mở mang đầu óc, giống như có người vẽ đường cho mình đi trong nghề DevOps vậy. Một số trải nghiệm đáng nhớ:\nHọc từ các anh đi trước (Speakers) Các chuyên gia từ FACJ chia sẻ rất thật về công việc DevOps hàng ngày. Được xem demo trực tiếp về cách giám sát hệ thống, nhìn rất chuyên nghiệp. Khám phá CI/CD và IaC Hiểu được các công ty lớn họ update phần mềm liên tục như thế nào nhờ CI/CD pipeline. Biết cách viết code để dựng hạ tầng (dùng CloudFormation/CDK) thay vì chỉnh tay từng chút một. Giám sát hệ thống Biết thêm về cách đặt cảnh báo (alerting) và xem dashboard, cũng như quy trình trực sự cố (on-call). Một số hình ảnh tại sự kiện Tóm lại, sự kiện này giúp mình có cái nhìn toàn cảnh về nghề DevOps. Quan trọng hơn là học được mấy cái \u0026ldquo;bí kíp\u0026rdquo; (best practice) để áp dụng CI/CD và giám sát hệ thống sao cho chuẩn bài.\n"
},
{
	"uri": "http://localhost:1313/fcj-workshop/vi/5-workshop/5.3-run-cloudformation-stack/",
	"title": "Thiết lập CloudFormation",
	"tags": [],
	"description": "",
	"content": "Tải xuống tài nguyên Tải xuống các tệp mẫu CloudFormation này:\nsmart_office_budget.yaml smart_office_s3_cloudfront.yaml smart_office_cognito.yaml smart_office_dynamodb.yaml smart_office_lambda_authenticate_with_dynamodb_cognito.yaml smart_office_lambda_readonly_with_dynamodb.yaml smart_office_lambda_crud_with_dynamodb_cognito.yaml smart_office_lambda_crud_with_dynamodb_iot.yaml smart_office_iot_core.yaml smart_office_api_gateway.yaml Triển khai các CloudFormation Stack Trong AWS Management Console, tìm kiếm và chọn CloudFormation Nhấp vào Create stack Tại mục Prepare template, tích chọn Choose an existing template Tại mục Template source, tích chọn Upload a template file Nhấp vào Choose file Chọn tệp smart_office_budget.yaml Nhấp vào Next Tại mục Stack name, nhập SmartOffice-Budget-Dev Nhấp vào Next Thêm Tags để quản lý chi phí và vận hành (Key: Project, Value: SmartOffice; Key: Environment, Value: Dev) Tại mục Stack failure options, tích chọn Preserve successfully provisioned resources (Để giữ lại tài nguyên đã tạo phục vụ việc gỡ lỗi) Nhấp vào Next Kiểm tra lại và nhấp vào Submit Thực hiện tương tự cho các tệp khác với tên chính xác như sau Tên Template Tên Stack smart_office_s3_cloudfront.yaml SmartOffice-S3-CloudFront-Dev smart_office_cognito.yaml SmartOffice-Cognito-Dev smart_office_dynamodb.yaml SmartOffice-DynamoDB-Dev smart_office_lambda_authenticate_with_dynamodb_cognito.yaml SmartOffice-Authenticate-Lambda-Dev smart_office_lambda_readonly_with_dynamodb.yaml SmartOffice-ReadOnly-Lambda-Dev smart_office_lambda_crud_with_dynamodb_cognito.yaml SmartOffice-Crud-Lambda-Dev smart_office_lambda_crud_with_dynamodb_iot.yaml SmartOffice-IoT-Lambda-Dev smart_office_iot_core.yaml SmartOffice-IoT-Core-Dev smart_office_api_gateway.yaml SmartOffice-API-Gateway-Dev "
},
{
	"uri": "http://localhost:1313/fcj-workshop/vi/4-eventparticipated/",
	"title": "Các events đã tham gia",
	"tags": [],
	"description": "",
	"content": "Sự kiện 1 Tên sự kiện: Vietnam Cloud Day HCMC Connect Edition (Track GenAI \u0026amp; Data)\nThời gian: 08:30, ngày 26 tháng 9 năm 2025\nĐịa điểm: Tầng 26, Tháp Bitexco, số 02 Hải Triều, Phường Bến Nghé, Quận 1, TP.HCM\nVai trò: Người tham dự\nMô tả: Đây là một sự kiện lớn về công nghệ đám mây, và mình đã chọn tham gia track chuyên sâu về GenAI và Dữ liệu. Các diễn giả từ AWS và đối tác (như TymeX) đã chia sẻ về tầm quan trọng của việc xây dựng một \u0026ldquo;nền móng\u0026rdquo; dữ liệu thống nhất (Unified Data Foundation) để nuôi AI. Mình được tìm hiểu cách phá vỡ các \u0026ldquo;kho\u0026rdquo; dữ liệu cô lập (silos) và sử dụng Amazon Bedrock để xây dựng ứng dụng AI nhanh chóng mà không cần lo quá nhiều về hạ tầng phức tạp bên dưới.\nKết quả thu được: Mình thấm thía tư duy \u0026ldquo;Dữ liệu là nhiên liệu cho AI\u0026rdquo; - dữ liệu có sạch và quy hoạch tốt thì AI mới thông minh được. Mình biết thêm về xu hướng Zero-ETL giúp giảm bớt công đoạn chuyển dữ liệu thủ công mệt mỏi. Phần chia sẻ thực tế (case study) của TymeX về ngành tài chính giúp mình tin tưởng hơn rằng GenAI không chỉ là trào lưu mà thực sự giải quyết được bài toán doanh nghiệp.\nSự kiện 2 Tên sự kiện: AWS Cloud Mastery Series #1: AI/ML/GenAI on AWS\nThời gian: 08:30, ngày 15 tháng 11 năm 2025\nĐịa điểm: Tầng 26, Tháp Bitexco, số 02 Hải Triều, Phường Bến Nghé, Quận 1, TP.HCM\nVai trò: Người tham dự\nMô tả: Một buổi giới thiệu nhập môn về các Mô hình nền tảng (Foundation Models) và Generative AI sử dụng Amazon Bedrock. Các diễn giả đã hướng dẫn cách viết câu lệnh (prompt) sao cho hiệu quả (kỹ thuật Chain of Thought) và giải thích về kiến trúc RAG để giúp AI sử dụng dữ liệu nội bộ của mình. Mình cũng được tìm hiểu chi tiết về vector embeddings và điểm qua các dịch vụ AI khác nhau của AWS.\nKết quả thu được: Mình đã học được rất nhiều về cách giảm thiểu việc AI \u0026ldquo;chém gió\u0026rdquo; (ảo giác) bằng cách dùng RAG và Embeddings. Mình biết được dịch vụ AI nào của AWS phù hợp cho từng bài toán cụ thể. Sự kiện mang lại những góc nhìn giá trị về việc xây dựng AI agent và là cơ hội tốt để mình nghe chia sẻ từ các chuyên gia trong ngành.\nSự kiện 3 Tên sự kiện: AWS Cloud Mastery Series #2: DevOps on AWS\nThời gian: 08:30, ngày 17 tháng 11 năm 2025\nĐịa điểm: Tầng 26, Tháp Bitexco, số 02 Hải Triều, Phường Bến Nghé, Quận 1, TP.HCM\nVai trò: Người tham dự\nMô tả: Một cái nhìn toàn cảnh về tư duy DevOps, nhấn mạnh vào làm việc nhóm và tự động hóa mọi thứ. Buổi học bao gồm các dịch vụ AWS DevOps cốt lõi như quy trình CI/CD, Cơ sở hạ tầng bằng mã (IaC - dùng code để dựng server) với CloudFormation, và quản lý container dùng EKS. Các anh cũng chia sẻ danh sách \u0026ldquo;Nên và Không nên\u0026rdquo; cho người mới bắt đầu hành trình DevOps và các mẹo để giám sát hệ thống.\nKết quả thu được: Mình có được một lộ trình rõ ràng hơn cho sự nghiệp DevOps và hiểu sâu hơn về vòng đời ứng dụng. Mình học được cách triển khai CI/CD pipeline và dùng các mẫu code (IaC) để hạn chế lỗi do thao tác tay. Mình cũng nắm được thêm kiến thức về việc giám sát sức khỏe hệ thống thông qua các ví dụ thực tế.\nSự kiện 4 Tên sự kiện: AWS Cloud Mastery Series #3: Theo AWS Well-Architected Security Pillar\nThời gian: 08:30, ngày 29 tháng 11 năm 2025\nĐịa điểm: Tầng 26, Tháp Bitexco, số 02 Hải Triều, Phường Bến Nghé, Quận 1, TP.HCM\nVai trò: Người tham dự\nMô tả: Đi sâu vào vấn đề bảo mật trên AWS, bao gồm quản lý Danh tính, Bảo vệ hạ tầng và Dữ liệu. Buổi này khám phá các biện pháp bảo mật nền tảng như phân quyền và MFA, nhưng cũng nói về các chiến lược nâng cao như \u0026ldquo;Detection-as-Code\u0026rdquo; để tự động tìm mối đe dọa bằng code và thiết lập quy trình phản ứng tự động.\nKết quả thu được: Mình hiểu tại sao việc không cấp quyền lung tung (nguyên tắc đặc quyền tối thiểu) lại quan trọng và cách thực hiện nó hiệu quả. Mình học được vài kỹ năng thực tế về việc cài đặt cảnh báo tự động khi có gì đó khả nghi. Buổi học nhấn mạnh rằng trong bảo mật, phòng bệnh hơn chữa bệnh để giảm thiểu rủi ro.\n"
},
{
	"uri": "http://localhost:1313/fcj-workshop/vi/4-eventparticipated/4.4-event4/",
	"title": "Event 4",
	"tags": [],
	"description": "",
	"content": "Báo cáo tổng hợp: \u0026ldquo;AWS Cloud Mastery Series #3: Theo AWS Well-Architected Security Pillar\u0026rdquo; Mục tiêu buổi học Nắm nền tảng về Bảo mật (Security Foundation). Quản lý xem ai được vào và được làm gì (Identity \u0026amp; Access Management). Phát hiện kẻ xấu (Detection). Bảo vệ hạ tầng và dữ liệu (Infrastructure \u0026amp; Data Protection). Làm gì khi \u0026ldquo;có biến\u0026rdquo; (Incident Response). Diễn giả Le Vu Xuan An Tran Duc Anh Tran Doan Cong Ly Danh Hoang Hieu Nghi Thinh Lam Viet Nguyen Mendel Branski (Long) Những điểm hay ho mình ghi lại được Giới thiệu về Cloud Club Biết thêm về các CLB Cloud tại trường đại học như UTE, SGU. Rất vui khi thấy cộng đồng sinh viên hoạt động sôi nổi. Nền tảng bảo mật SCPs: Luật chơi chung cho toàn bộ tổ chức, không ai được phá. Permission Boundaries: Đặt giới hạn để không ai có quyền lực quá lớn. MFA: Cái này bắt buộc phải có để bảo vệ tài khoản. Phát hiện và Giám sát Bảo mật nhiều lớp: Kiểm tra ở mọi ngóc ngách chứ không chỉ ở cửa ra vào. Cảnh báo (Alerting): Dùng EventBridge để hệ thống tự \u0026ldquo;la làng\u0026rdquo; khi có gì đó đáng ngờ. Detection-as-Code: Dùng code để tự động phát hiện mối đe dọa (nghe rất ngầu và tiện). Ứng phó sự cố (Incident Response) Phòng ngừa: Cách tốt nhất để xử lý sự cố là đừng để nó xảy ra. \u0026ldquo;Ngủ ngon hơn\u0026rdquo;: Thiết lập hệ thống tốt để đêm không bị dựng dậy sửa lỗi. Quy trình từng bước để xử lý khi hệ thống bị tấn công hoặc sập. Bài học rút ra Service Control Policies (SCPs) Coi cái này như \u0026ldquo;Hiến pháp\u0026rdquo; của tài khoản AWS vậy. Nó kiểm soát quyền hạn tối đa. Dù bạn là Admin, nhưng SCP bảo \u0026ldquo;Cấm\u0026rdquo; thì là Cấm. Nó không bao giờ cấp quyền, nó chỉ dùng để chặn/lọc quyền thôi. Permission Boundaries Một cách để ngăn chặn người dùng (hoặc Role) tự cấp quyền quá cao cho bản thân. Nó tạo ra một cái \u0026ldquo;trần\u0026rdquo; quyền hạn không thể vượt qua. Multi-Factor Authentication (MFA) - Phải dùng! TOTP: Mã 6 số trên Google Authenticator. Miễn phí, dễ dùng, sao lưu linh hoạt. FIDO2: Khóa vật lý (USB) chạm vào là xong. Bảo mật cao hơn, khó bị hack hơn nhưng tốn tiền mua khóa. Detection-as-Code Dùng các công cụ như CloudFormation/Terraform để tự động bật GuardDuty (trình phát hiện mối đe dọa) trên toàn bộ hệ thống. Quản lý phiên bản: Lưu các luật bảo mật trên Git để theo dõi thay đổi y như code phần mềm. Ứng phó sự cố Chuẩn bị: Phải có tool tự động trước khi sự cố xảy ra. Rút kinh nghiệm: Sau khi sửa xong, luôn phải họp lại để xem tại sao bị lỗi để lần sau không bị nữa. Áp dụng vào công việc Nguyên tắc đặc quyền tối thiểu: Rà soát lại dự án, chỉ cấp quyền vừa đủ dùng, không cấp Admin lung tung nữa. Bật MFA: Bắt buộc tất cả các tài khoản phải có xác thực 2 bước. Dự đoán: Luôn tự hỏi \u0026ldquo;Lỡ cái này hỏng thì sao?\u0026rdquo; và chuẩn bị sẵn phương án. Trải nghiệm tham gia Tham gia buổi workshop “Theo AWS Well-Architected Security Pillar” giúp mình nhận ra bảo mật không chỉ là cài firewall, mà là cả một tư duy hệ thống.\nHọc từ các đàn anh (Senior) Nghe các anh Senior chia sẻ về cách xử lý khi \u0026ldquo;có biến\u0026rdquo; (incident) rất thực tế. Các anh nhấn mạnh nhiều vào việc \u0026ldquo;học được gì sau sự cố\u0026rdquo; thay vì chỉ lo sửa cho xong. Giao lưu với Cloud Club Được biết thêm về các hoạt động của Cloud Club, nơi kết nối những người học AWS từ khắp nơi. Cảnh báo \u0026amp; Tự động hóa Hiểu rằng mình không thể trực màn hình 24/7. Phải biết dùng CloudTrail, EventBridge để hệ thống tự canh gác và báo động ngay lập tức khi có vấn đề. Tóm lại, sự kiện này là cơ hội để mình mở rộng kiến thức về Tự động hóa và Bảo mật. Mình hiểu ra bảo mật không chỉ là khóa cửa, mà là có hệ thống báo động thông minh và biết phải làm gì khi chuông báo động reo.\n"
},
{
	"uri": "http://localhost:1313/fcj-workshop/vi/5-workshop/5.4-set-up-website/",
	"title": "Thiết lập website",
	"tags": [],
	"description": "",
	"content": "Thiết lập Gitlab repository để triển khai website và lambda code Truy cập Gitlab repository này: https://gitlab.com/tranngockhiet22062005/smart-office Tải xuống và triển khai trên repository của riêng bạn Thiết lập role cho Gitlab để triển khai website lên S3 và triển khai code lên Lambda Function Tạo một IAM User với các thuộc tính sau (xem lại phần 5.2 nếu bạn quên) User name: smart-office-gitlab-ci Policy: { \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Sid\u0026#34;: \u0026#34;S3ListBucketAccess\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;s3:ListBucket\u0026#34;, \u0026#34;s3:GetBucketLocation\u0026#34; ], \u0026#34;Resource\u0026#34;: [ \u0026#34;arn:aws:s3:::fcj-smart-office-frontend-ACCOUNT_ID-dev\u0026#34;, \u0026#34;arn:aws:s3:::fcj-smart-office-lambda-ACCOUNT_ID-dev\u0026#34; ] }, { \u0026#34;Sid\u0026#34;: \u0026#34;S3ReadWriteAccess\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;s3:PutObject\u0026#34;, \u0026#34;s3:GetObject\u0026#34;, \u0026#34;s3:DeleteObject\u0026#34;, \u0026#34;s3:PutObjectAcl\u0026#34; ], \u0026#34;Resource\u0026#34;: [ \u0026#34;arn:aws:s3:::fcj-smart-office-frontend-ACCOUNT_ID-dev/*\u0026#34;, \u0026#34;arn:aws:s3:::fcj-smart-office-lambda-ACCOUNT_ID-dev/*\u0026#34; ] }, { \u0026#34;Sid\u0026#34;: \u0026#34;LambdaUpdateAccess\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;lambda:UpdateFunctionCode\u0026#34;, \u0026#34;lambda:GetFunction\u0026#34;, \u0026#34;lambda:GetFunctionConfiguration\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:lambda:*:*:function:SmartOffice-*\u0026#34; }, { \u0026#34;Sid\u0026#34;: \u0026#34;CloudFrontInvalidation\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;cloudfront:CreateInvalidation\u0026#34;, \u0026#34;cloudfront:GetDistribution\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;*\u0026#34; } ] } Bạn nên thay thế ACCOUNT_ID bằng AWS Account ID của bạn\rPolicy name: SmartOfficeGitlabAccess Điều hướng đến user đó Trong phần Summary, nhấp vào Create access key Tại mục Use case, tích chọn Command Line Interface (CLI) Tích chọn I understand the above recommendation and want to proceed to create an access key. Nhấp Next Nhấp Create access key Nhấp Download .csv file Cấu hình các biến Gitlab Truy cập Gitlab repository của bạn, nhấp vào Setting \u0026gt; Variables Nhấp Add variable Đối với mỗi Key và Value, hãy làm theo bảng dưới đây để biết nơi lấy giá trị\nKey Value AWS_ACCESS_KEY_ID In your smart-office-gitlab-ci_accessKeys.csv you have downloaded AWS_DEFAULT_REGION ap-southeast-1 (or anywhere you deploy the workshop) AWS_SECRET_ACCESS_KEY In your smart-office-gitlab-ci_accessKeys.csv you have downloaded CLOUDFRONT_DISTRIBUTION_ID CloudFront \u0026gt; Distributions \u0026gt; Your distribution ID S3_BUCKET_FRONTEND fcj-smart-office-frontend-ACCOUNT_ID-dev (replace ACCOUNT_ID with your AWS Account ID) S3_BUCKET_LAMBDA fcj-smart-office-lambda-ACCOUNT_ID-dev (replace ACCOUNT_ID with your AWS Account ID) STACK_NAME_AUTH SmartOffice-Authenticate-Lambda-Dev STACK_NAME_CRUD SmartOffice-Crud-Lambda-Dev STACK_NAME_IOT SmartOffice-IoT-Lambda-Dev STACK_NAME_READONLY SmartOffice-ReadOnly-Lambda-Dev VITE_API_BASE_URL API Gateway \u0026gt; SmartOffice-API-Gateway-Dev-Api \u0026gt; Stages \u0026gt; Invoke URL Push code vào nhánh init\nMerge các branch theo thứ tự sau: init -\u0026gt; dev, dev -\u0026gt; main\n"
},
{
	"uri": "http://localhost:1313/fcj-workshop/vi/5-workshop/5.5-event-bridge/",
	"title": "Thiết lập EventBridge và Lambda",
	"tags": [],
	"description": "",
	"content": "Tổng quan Phần này sẽ hướng dẫn bạn cách thiết lập Amazon EventBridge và Lambda để định tuyến và phản ứng với các sự kiện xảy ra trong DynamoDB. Để thiết lập SNS (được sử dụng để gửi cảnh báo), vui lòng tham khảo phần 5.6 - Thiết lập SNS.\nTạo AutomationSetup (Lambda + rules) Tạo một hàm Lambda (AutomationSetup) có nhiệm vụ đọc cấu hình tự động từ DynamoDB và xác định hai rule EventBridge: một để bật tự động hoá và một khác để tắt tự động hoá. import boto3\rimport json\rimport os\rfrom boto3.dynamodb.types import TypeDeserializer\rdeserializer = TypeDeserializer()\revents_client = boto3.client(\u0026#39;events\u0026#39;)\rHANDLER_ARN = os.environ.get(\u0026#39;HANDLER_LAMBDA_ARN\u0026#39;) def ddb_deserialize(image):\rd = {}\rfor key in image:\rd[key] = deserializer.deserialize(image[key])\rreturn d\rdef time_to_cron(time_str):\rtry:\rhour, minute = map(int, time_str.split(\u0026#39;:\u0026#39;))\rutc_hour = hour - 7\rif utc_hour \u0026lt; 0: utc_hour += 24\rreturn f\u0026#34;cron({minute} {utc_hour} * * ? *)\u0026#34;\rexcept: return None\r# --- CẬP NHẬT 1: Thêm tham số office_id vào hàm ---\rdef create_or_update_schedule(room_id, office_id, time_str, action):\rrule_name = f\u0026#34;Room_{room_id}_Auto_{action}\u0026#34;\rcron_expr = time_to_cron(time_str)\rif not cron_expr: return\rprint(f\u0026#34;Updating Rule: {rule_name} with Input\u0026#34;)\revents_client.put_rule(\rName=rule_name,\rScheduleExpression=cron_expr,\rState=\u0026#39;ENABLED\u0026#39;,\rDescription=f\u0026#39;Auto {action} for {room_id} in {office_id}\u0026#39;\r)\r# --- CẬP NHẬT 2: Thêm officeId vào JSON Input ---\rtarget_input = json.dumps({\r\u0026#34;roomId\u0026#34;: room_id,\r\u0026#34;officeId\u0026#34;: office_id, # \u0026lt;--- QUAN TRỌNG: Bao gồm officeId\r\u0026#34;command\u0026#34;: action.upper(), \u0026#34;source\u0026#34;: \u0026#34;Scheduled_Event\u0026#34;\r})\revents_client.put_targets(\rRule=rule_name,\rTargets=[{\r\u0026#39;Id\u0026#39;: \u0026#39;1\u0026#39;, \u0026#39;Arn\u0026#39;: HANDLER_ARN, \u0026#39;Input\u0026#39;: target_input }]\r)\rdef lambda_handler(event, context):\rprint(\u0026#34;Raw Event:\u0026#34;, json.dumps(event))\rif \u0026#39;Records\u0026#39; in event:\rfor record in event[\u0026#39;Records\u0026#39;]:\rif record[\u0026#39;eventName\u0026#39;] in [\u0026#39;INSERT\u0026#39;, \u0026#39;MODIFY\u0026#39;]:\rraw_image = record[\u0026#39;dynamodb\u0026#39;][\u0026#39;NewImage\u0026#39;]\rdata = ddb_deserialize(raw_image)\rroom_id = data.get(\u0026#39;roomId\u0026#39;)\r# --- CẬP NHẬT 3: Lấy officeId từ DynamoDB ---\roffice_id = data.get(\u0026#39;officeId\u0026#39;) auto_control = data.get(\u0026#39;autoControl\u0026#39;)\rauto_on = data.get(\u0026#39;autoOnTime\u0026#39;)\rauto_off = data.get(\u0026#39;autoOffTime\u0026#39;)\rif auto_control == \u0026#34;ON\u0026#34; and room_id:\r# Chuyển office_id tới hàm tạo lịch biểu\rif auto_on: create_or_update_schedule(room_id, office_id, auto_on, \u0026#39;ON\u0026#39;)\rif auto_off: create_or_update_schedule(room_id, office_id, auto_off, \u0026#39;OFF\u0026#39;)\rreturn {\u0026#39;statusCode\u0026#39;: 200, \u0026#39;body\u0026#39;: \u0026#39;Processed\u0026#39;} Đi tới Configuration \u0026ndash;\u0026gt; Trigger để cấu hình các trigger Lambda — điều này sẽ được sử dụng để gọi lambda bất cứ khi nào có luồng mới từ DynamoDB Chọn Add Trigger, chọn DynamoDB và chọn bảng chứa cấu hình phòng. Trong Configuration \u0026ndash;\u0026gt; Environment Variable, thêm cặp khóa-giá trị này (thay thế tương ứng bằng thông tin cá nhân của bạn) Chọn Configuration \u0026ndash;\u0026gt;Role name, và đảm bảo bạn có 3 chính sách này: AutomationSetup_RuleExecuiton để tạo rule trong EventBridge AWSLambdaBasicExecutionRole cho quyền thực thi lambda cơ bản AWSLambdaDynamoDBExecutionRole để tương tác với DynamoDB. {\r\u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;,\r\u0026#34;Statement\u0026#34;: [\r{\r\u0026#34;Sid\u0026#34;: \u0026#34;VisualEditor0\u0026#34;,\r\u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;,\r\u0026#34;Action\u0026#34;: [\r\u0026#34;events:DeleteRule\u0026#34;,\r\u0026#34;events:PutTargets\u0026#34;,\r\u0026#34;events:EnableRule\u0026#34;,\r\u0026#34;events:PutRule\u0026#34;,\r\u0026#34;events:DisableRule\u0026#34;\r],\r\u0026#34;Resource\u0026#34;: \u0026#34;*\u0026#34;\r}\r]\r} Chỉ dành cho AutomationSetup_RuleExecuiton, chọn Add permissions \u0026ndash;\u0026gt; Create inline policy\n{\r\u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;,\r\u0026#34;Statement\u0026#34;: [\r{\r\u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;,\r\u0026#34;Action\u0026#34;: \u0026#34;logs:CreateLogGroup\u0026#34;,\r\u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:logs:ap-southeast-1:261899902491:*\u0026#34;\r},\r{\r\u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;,\r\u0026#34;Action\u0026#34;: [\r\u0026#34;logs:CreateLogStream\u0026#34;,\r\u0026#34;logs:PutLogEvents\u0026#34;\r],\r\u0026#34;Resource\u0026#34;: [\r\u0026#34;arn:aws:logs:ap-southeast-1:261899902491:log-group:/aws/lambda/AutomationSetup:*\u0026#34;\r]\r}\r]\r} AWSLambdaBasicExecutionRole\n{\r\u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;,\r\u0026#34;Statement\u0026#34;: [\r{\r\u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;,\r\u0026#34;Action\u0026#34;: [\r\u0026#34;dynamodb:DescribeStream\u0026#34;,\r\u0026#34;dynamodb:GetRecords\u0026#34;,\r\u0026#34;dynamodb:GetShardIterator\u0026#34;,\r\u0026#34;dynamodb:ListStreams\u0026#34;,\r\u0026#34;logs:CreateLogGroup\u0026#34;,\r\u0026#34;logs:CreateLogStream\u0026#34;,\r\u0026#34;logs:PutLogEvents\u0026#34;\r],\r\u0026#34;Resource\u0026#34;: \u0026#34;*\u0026#34;\r}\r]\r} AWSLambdaDynamoDBExecutionRole\nHai rule này tương ứng với hành vi tự động hoá BẬT và TẮT.\nTạo AutomationHandler (Lambda để chuyển tiếp các sự kiện tới AWS IoT Core) Tạo Lambda AutomationHandler để nhận các sự kiện từ EventBridge và chuyển tiếp chúng tới AWS IoT Core. import boto3\rimport json\rimport logging\rlogger = logging.getLogger()\rlogger.setLevel(logging.INFO)\riot_client = boto3.client(\u0026#39;iot-data\u0026#39;, region_name=\u0026#39;ap-southeast-1\u0026#39;)\rdef lambda_handler(event, context):\r\u0026#34;\u0026#34;\u0026#34;\rĐầu vào từ EventBridge: {\u0026#34;roomId\u0026#34;: \u0026#34;test2\u0026#34;, \u0026#34;officeId\u0026#34;: \u0026#34;...\u0026#34;, \u0026#34;command\u0026#34;: \u0026#34;ON\u0026#34;, ...}\r\u0026#34;\u0026#34;\u0026#34;\r# Ghi nhật ký toàn bộ sự kiện để xác minh tải trọng\rlogger.info(f\u0026#34;Executing Automation: {json.dumps(event)}\u0026#34;)\r# 1. Trích xuất dữ liệu từ Sự kiện\rroom_id = event.get(\u0026#39;roomId\u0026#39;)\rcommand = event.get(\u0026#39;command\u0026#39;) # BẬT / TẮT\roffice_id = event.get(\u0026#39;officeId\u0026#39;) # 2. Xác thực dữ liệu đầu vào\rif not room_id or not command:\rlogger.error(\u0026#34;Missing roomId or command\u0026#34;)\rreturn {\u0026#39;statusCode\u0026#39;: 400, \u0026#39;body\u0026#39;: \u0026#39;Missing roomId or command\u0026#39;}\rif not office_id:\rlogger.error(\u0026#34;Missing officeId\u0026#34;)\rreturn {\u0026#39;statusCode\u0026#39;: 400, \u0026#39;body\u0026#39;: \u0026#39;Missing officeId\u0026#39;}\r# 3. Tạo Chủ đề và Tải trọng\rtopic = f\u0026#34;office/{office_id}/room/{room_id}/config\u0026#34;\rpayload = {\r\u0026#34;command\u0026#34;: \u0026#34;SET_STATE\u0026#34;,\r\u0026#34;value\u0026#34;: command,\r\u0026#34;triggeredBy\u0026#34;: \u0026#34;Schedule\u0026#34;\r}\r# 4. Gửi lệnh tới IoT Core\rtry:\r# Dòng này phải được căn chỉnh với các dòng ở trên\rresponse = iot_client.publish(\rtopic=topic,\rqos=1,\rpayload=json.dumps(payload)\r)\rlogger.info(f\u0026#34;SUCCESS: Sent {command} to {topic}\u0026#34;)\rreturn {\u0026#39;statusCode\u0026#39;: 200, \u0026#39;body\u0026#39;: \u0026#39;Command sent\u0026#39;}\rexcept Exception as e:\rlogger.error(f\u0026#34;IoT Publish Error: {e}\u0026#34;)\r# Nâng cao lỗi để EventBridge biết nó không thành công (kích hoạt Retry/DLQ)\rraise e Đi tới Configuration \u0026ndash;\u0026gt; Permissions và thêm resource-based policy. (Để cho phép EventBridge truy cập hàm lambda này) Thêm rule được tạo bởi AutomationSetup làm kích hoạt cho Lambda này. Thay thế REGION, ACCOUNT, ARNs và tên tài nguyên bằng các giá trị từ tài khoản của bạn trước khi chạy.\n"
},
{
	"uri": "http://localhost:1313/fcj-workshop/vi/5-workshop/",
	"title": "Workshop",
	"tags": [],
	"description": "",
	"content": "Đảm bảo truy cập Hybrid an toàn đến S3 bằng cách sử dụng VPC endpoint Tổng quan AWS PrivateLink cung cấp kết nối riêng tư đến các dịch vụ aws từ VPCs hoặc trung tâm dữ liệu (on-premise) mà không làm lộ lưu lượng truy cập ra ngoài public internet.\nTrong bài lab này, chúng ta sẽ học cách tạo, cấu hình, và kiểm tra VPC endpoints để cho phép workload của bạn tiếp cận các dịch vụ AWS mà không cần đi qua Internet công cộng.\nChúng ta sẽ tạo hai loại endpoints để truy cập đến Amazon S3: gateway vpc endpoint và interface vpc endpoint. Hai loại vpc endpoints này mang đến nhiều lợi ích tùy thuộc vào việc bạn truy cập đến S3 từ môi trường cloud hay từ trung tâm dữ liệu (on-premise).\nGateway - Tạo gateway endpoint để gửi lưu lượng đến Amazon S3 hoặc DynamoDB using private IP addresses. Bạn điều hướng lưu lượng từ VPC của bạn đến gateway endpoint bằng các bảng định tuyến (route tables) Interface - Tạo interface endpoint để gửi lưu lượng đến các dịch vụ điểm cuối (endpoints) sử dụng Network Load Balancer để phân phối lưu lượng. Lưu lượng dành cho dịch vụ điểm cuối được resolved bằng DNS. Nội dung Tổng quan về workshop Chuẩn bị Truy cập đến S3 từ VPC Truy cập đến S3 từ TTDL On-premises VPC Endpoint Policies (làm thêm) Dọn dẹp tài nguyên "
},
{
	"uri": "http://localhost:1313/fcj-workshop/vi/6-self-evaluation/",
	"title": "Tự đánh giá",
	"tags": [],
	"description": "",
	"content": "Trong suốt thời gian thực tập tại Công ty TNHH Amazon Web Services Vietnam từ 06/08/2025 đến 24/12/2025, tôi đã có cơ hội học hỏi, rèn luyện và áp dụng kiến thức đã được trang bị tại trường vào môi trường làm việc thực tế.\nTôi đã tham gia Dụ án Smart Office, qua đó cải thiện kỹ năng sử dụng các dịch vụ của AWS, làm việc nhóm, cấu hình CI/CD pipeline và lập trình Web.\nVề tác phong, tôi luôn cố gắng hoàn thành tốt nhiệm vụ, tuân thủ nội quy, và tích cực trao đổi với đồng nghiệp để nâng cao hiệu quả công việc.\nĐể phản ánh một cách khách quan quá trình thực tập, tôi xin tự đánh giá bản thân dựa trên các tiêu chí dưới đây:\nSTT Tiêu chí Mô tả Tốt Khá Trung bình 1 Kiến thức và kỹ năng chuyên môn Hiểu biết về ngành, áp dụng kiến thức vào thực tế, kỹ năng sử dụng công cụ, chất lượng công việc ☐ ✅ ☐ 2 Khả năng học hỏi Tiếp thu kiến thức mới, học hỏi nhanh ☐ ✅ ☐ 3 Chủ động Tự tìm hiểu, nhận nhiệm vụ mà không chờ chỉ dẫn ✅ ☐ ☐ 4 Tinh thần trách nhiệm Hoàn thành công việc đúng hạn, đảm bảo chất lượng ✅ ☐ ☐ 5 Kỷ luật Tuân thủ giờ giấc, nội quy, quy trình làm việc ✅ ☐ ☐ 6 Tính cầu tiến Sẵn sàng nhận feedback và cải thiện bản thân ✅ ☐ ☐ 7 Giao tiếp Trình bày ý tưởng, báo cáo công việc rõ ràng ☐ ✅ ☐ 8 Hợp tác nhóm Làm việc hiệu quả với đồng nghiệp, tham gia nhóm ☐ ✅ ☐ 9 Ứng xử chuyên nghiệp Tôn trọng đồng nghiệp, đối tác, môi trường làm việc ✅ ☐ ☐ 10 Tư duy giải quyết vấn đề Nhận diện vấn đề, đề xuất giải pháp, sáng tạo ☐ ✅ ☐ 11 Đóng góp vào dự án/tổ chức Hiệu quả công việc, sáng kiến cải tiến, ghi nhận từ team ✅ ☐ ☐ 12 Tổng thể Đánh giá chung về toàn bộ quá trình thực tập ✅ ☐ ☐ Cần cải thiện Cải thiện trong cách tư duy giải quyết vấn đề Học cách giao tiếp tốt hơn trong giao tiếp hằng ngày và trong công việc, xử lý tình huống Nâng cao kỹ năng làm việc nhóm để hoàn thành workshop nhanh hơn "
},
{
	"uri": "http://localhost:1313/fcj-workshop/vi/5-workshop/5.6-sns/",
	"title": "Thiết lập SNS",
	"tags": [],
	"description": "",
	"content": "Tổng quan Phần này sẽ hướng dẫn bạn cách thiết lập Amazon SNS (Dịch vụ Thông báo Đơn giản) để nhận cảnh báo từ EventBridge khi phát hiện bất thường dữ liệu.\nTạo Topic SNS Đi tới Bảng điều khiển Amazon SNS Chọn Topic và đặt tên cho Topic của bạn KHÔNG BẬT MÃ HÓA\nTạo Subscription SNS Sau khi tạo chủ đề, hãy tạo một hoặc nhiều đăng ký để cảnh báo được gửi đến người nhận hoặc điểm cuối (trong trường hợp này, email).\nCác bước:\nChọn Subscription trong SNS Chọn giao thức email, chọn topic bạn vừa tạo và ghi lại email bạn muốn kiểm tra. Các điểm cuối email yêu cầu xác nhận trước khi nhận các tin nhắn. Kiểm tra hộp thư của bạn để tìm email xác nhận từ AWS SNS và xác nhận đăng ký.\nTạo một rule và gắn nó vào topic SNS Đi tới Bảng điều khiển Amazon EventBridge Chọn Rules và tạo một rule mới Ở bước 2, chúng tôi xác định mẫu sự kiện bằng cách chọn Custom pattern. Các mẫu sự kiện có thể khớp với source, detail-type.\nSử dụng Json sau:\n{\r\u0026#34;source\u0026#34;: [\u0026#34;com.smartoffice.iot\u0026#34;],\r\u0026#34;detail-type\u0026#34;: [\u0026#34;sensor.anomaly\u0026#34;]\r} Ở bước 3, chọn mục tiêu cho quy tắc — chọn topic SNS bạn đã tạo trước đó. Sau khi tạo, EventBridge sẽ chuyển tiếp các sự kiện phù hợp đến topic SNS sẽ chuyển đến các đăng ký của nó.\nThay thế địa chỉ email và tên tài nguyên bằng các giá trị từ tài khoản của bạn trước khi chạy.\n"
},
{
	"uri": "http://localhost:1313/fcj-workshop/vi/7-feedback/",
	"title": "Chia sẻ, đóng góp ý kiến",
	"tags": [],
	"description": "",
	"content": "Đánh giá tổng quan 1. Môi trường làm việc Môi trường ở đây thực sự rất thoải mái và cởi mở. Các anh chị trong FCJ cực kỳ thân thiện, không tạo cảm giác khoảng cách giữa sếp và nhân viên. Văn phòng ở Bitexco thì \u0026ldquo;xịn sò\u0026rdquo;, view đẹp giúp mình có thêm động lực đi làm mỗi ngày.\n2. Sự hỗ trợ từ Mentor / Team Admin Mentor của mình hướng dẫn rất có tâm. Thay vì chỉ đâu đánh đó, anh ấy thường gợi ý hướng giải quyết để mình tự mày mò, nhờ vậy mà mình nhớ lâu hơn. Các chị bên Admin cũng hỗ trợ nhiệt tình mấy vụ giấy tờ, tài khoản nên mình không gặp khó khăn gì lúc mới vào.\n3. Mức độ phù hợp với chuyên ngành Công việc thực tập rất sát với chuyên ngành CNTT của mình. Ở trường mình học lý thuyết nhiều, còn vào đây là được \u0026ldquo;thực chiến\u0026rdquo; với AWS, Server, Code\u0026hellip; Nó giúp mình hiểu rõ những gì thầy cô dạy áp dụng vào thực tế như thế nào.\n4. Cơ hội học hỏi và phát triển kỹ năng Ngoài kiến thức kỹ thuật (Cloud, DevOps), mình còn học được cả kỹ năng mềm như cách viết email chuyên nghiệp, cách viết blog kỹ thuật và cách làm việc nhóm. Những buổi workshop công ty tổ chức cũng giúp mình mở mang đầu óc rất nhiều.\n5. Văn hóa công ty và tinh thần đồng đội Văn hóa ở đây kiểu \u0026ldquo;làm hết sức, chơi hết mình\u0026rdquo;. Mọi người tôn trọng lẫn nhau và hỗ trợ nhau rất nhiệt tình khi dự án gấp. Mình cảm thấy mình là một phần của team chứ không chỉ là sinh viên thực tập.\n6. Chính sách / Phúc lợi thực tập Trợ cấp thực tập khá ổn. Điều mình thích nhất là công ty linh động thời gian, cho phép mình sắp xếp lịch làm việc để không bị cấn lịch học trên trường. Được tham gia các khóa training miễn phí cũng là một điểm cộng lớn.\nCâu hỏi bổ sung Điều gì làm bạn hài lòng nhất trong kỳ thực tập? Điều mình vui nhất là khi tự tay deploy thành công dự án lên AWS và thấy nó chạy ngon lành. Ngoài ra, việc được tham gia chuỗi sự kiện \u0026ldquo;AWS Cloud Mastery\u0026rdquo; và gặp gỡ các chuyên gia cũng là trải nghiệm mình rất thích.\nBạn nghĩ công ty nên cải thiện điều gì cho các bạn thực tập sinh sau? Mình nghĩ tài liệu hướng dẫn ban đầu (onboarding) nên chi tiết hơn một chút. Mấy ngày đầu mình hơi bỡ ngỡ không biết tìm tài liệu nội bộ ở đâu. Có một cái \u0026ldquo;Sổ tay nhập môn\u0026rdquo; thì sẽ tuyệt hơn.\nBạn có giới thiệu bạn bè vào thực tập không? Tại sao? Chắc chắn là CÓ. Nếu bạn mình muốn theo mảng Cloud/DevOps thì đây là chỗ lý tưởng. Vào đây là được làm thật, học thật chứ không phải chỉ ngồi chơi xơi nước.\nĐề xuất \u0026amp; Mong muốn Bạn có đề xuất gì để cải thiện trải nghiệm thực tập không? Sẽ hay hơn nếu có buổi \u0026ldquo;chia sẻ nội bộ\u0026rdquo; hàng tuần, nơi thực tập sinh có thể trình bày những gì mình mới học được để luyện kỹ năng thuyết trình trước đám đông.\nBạn có muốn tiếp tục chương trình này không? Hiện tại em vẫn chưa đưa ra quyết định cuối cùng ạ. Tuy nhiên, chắc chắn em sẽ tiếp tục theo đuổi và trau dồi thêm kiến thức về AWS.\nLời nhắn nhủ khác: Em xin gửi lời cảm ơn chân thành đến Mentor và các anh chị trong team đã kiên nhẫn chỉ bảo em trong suốt thời gian qua. Đây thực sự là bước đệm quan trọng cho sự nghiệp của em sau này.\n"
},
{
	"uri": "http://localhost:1313/fcj-workshop/vi/5-workshop/5.7-test-website-iot-connection/",
	"title": "Kiểm thử kết nối giữa website và thiết bị IoT",
	"tags": [],
	"description": "",
	"content": "Tải kịch bản giả lập thiết bị IoT main.py\nThêm dữ liệu cho thiết bị giả ENDPOINT = \u0026#34;\u0026#34; CLIENT_ID = \u0026#34;\u0026#34; OFFICE_ID = \u0026#34;\u0026#34; ROOM_ID = \u0026#34;\u0026#34; PATH_TO_CERT = \u0026#34;\u0026#34; PATH_TO_KEY = \u0026#34;\u0026#34; PATH_TO_ROOT = \u0026#34;\u0026#34; Thuộc tính Giá trị ENDPOINT Trên trang manager CLIENT_ID ID của office của bạn OFFICE_ID Tên office của bạn ROOM_ID ID phòng của bạn PATH_TO_CERT Đường dẫn tải xuống chứng chỉ thiết bị của bạn khi bạn tạo phòng PATH_TO_KEY Đường dẫn tải xuống khóa riêng của thiết bị khi bạn tạo phòng PATH_TO_ROOT Đường dẫn tải xuống chứng chỉ gốc Amazon của bạn khi bạn tạo phòng Link video demo https://www.youtube.com/watch?v=k45jHjkKhuc\n"
},
{
	"uri": "http://localhost:1313/fcj-workshop/vi/categories/",
	"title": "Categories",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "http://localhost:1313/fcj-workshop/vi/tags/",
	"title": "Tags",
	"tags": [],
	"description": "",
	"content": ""
}]